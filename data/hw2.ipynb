{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "name": "Homework 2 Release.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "trB1uensah2P",
        "colab_type": "text"
      },
      "source": [
        "# Classification of MNIST\n",
        "\n",
        "MNIST is a dataset consisting of handwritten numbers 0-9 widely used as a benchmark in machine learning. While the dataset is very simple, it is still in seminal papers to demonstrate proof of concept (i.e. [Dynamic Routing](https://arxiv.org/pdf/1710.09829.pdf)). Below we load some sample digits for you.\n",
        "\n",
        "Benchmark datasets are very useful, to note a couple other widely used benchmarks: [SVHN](http://ufldl.stanford.edu/housenumbers/) (Street View House Numbers), [Fashion MNIST](https://github.com/zalandoresearch/fashion-mnist) (Like MNIST, but more fashion), [CIFAR](https://www.cs.toronto.edu/~kriz/cifar.html) (10 and 100 different objects), and [ImageNet](http://www.image-net.org/) (very large real world image dataset).\n",
        "\n",
        "We load up a downsampled MNIST dataset below. MNIST is usually 28x28, but we will work with 8x8 images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7-YVby7ah2S",
        "colab_type": "code",
        "outputId": "255af38c-5bf3-4fc2-ef4b-27c6e7925ec2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "source": [
        "# Import datasets (just run this block)\n",
        "%matplotlib inline\n",
        "\n",
        "from sklearn import datasets\n",
        "import matplotlib.pyplot as plt\n",
        "digits = datasets.load_digits()\n",
        "for index, (image, label) in enumerate(list(zip(digits.images, digits.target))[:10]):\n",
        "    plt.subplot(1, 10, index + 1)\n",
        "    plt.axis('off')\n",
        "    plt.imshow(image, cmap=plt.cm.gray_r)\n",
        "    plt.title('%i' % label)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWoAAABLCAYAAABZX83EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nOSVqEZHMKVGLiGROiVpEJHNK1CIimfsvgGxDge7KSEgAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 10 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CaCC1cCQah2X",
        "colab_type": "text"
      },
      "source": [
        "# Part I\n",
        "\n",
        "You will classifiy two numbers of your choice. Start by extracting two features from the image. We suggest looking at intensity and symmetry using `sklearn.model_selection.train_test_split`, a convenient function which will save 10% of the data for testing. We split the dataset into training and test sets. Save your test set so we can evaluate how well you classify.\n",
        "\n",
        "`X_test` and `y_test` should be used to evaluate the performance of the classifier you build. Moving forward just work with `X_train` and `y_train`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g4q2uNiJah2Y",
        "colab_type": "code",
        "outputId": "591dbd1d-c975-49cb-d176-ac7fd63c2b83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 78
        }
      },
      "source": [
        "# in this block, you only need to modify number_a and number_b (if you wish to)\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "number_a = 0 # TODO choose your digit\n",
        "number_b = 3 # TODO choose your digit\n",
        "\n",
        "digit_a_indexes = np.where(digits.target==number_a) \n",
        "digit_b_indexes = np.where(digits.target==number_b)\n",
        "targets = np.concatenate((digits.target[digit_a_indexes], digits.target[digit_b_indexes]))\n",
        "images = np.concatenate((digits.images[digit_a_indexes], digits.images[digit_b_indexes]))\n",
        "X_train, X_test, y_train, y_test = train_test_split(images, targets, test_size=0.1, random_state=42)\n",
        "for index, image in enumerate(X_train[:10]):\n",
        "    plt.subplot(1, 10, index + 1)\n",
        "    plt.axis('off')\n",
        "    plt.imshow(image, cmap=plt.cm.gray_r)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWoAAAA9CAYAAACEJCMYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 10 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1t7_IoDhah2b",
        "colab_type": "text"
      },
      "source": [
        "# 1. Feature Extraction\n",
        "\n",
        "You will create 2 feature extractors based on the numbers you choose. These will be two functions which take in an image and output a single float. Please use mean or total intensity and a metric that quantifies symmetry. You may change the digits you wish to classify to make this classification problem easier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idT9Dhzhah2c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# please complete this function:\n",
        "def compute_features(vector):\n",
        "    image = vector.reshape(8, 8) # get back original image shape\n",
        "    def compute_feature_a(image):\n",
        "        '''compute_feature_a will compute ...'''\n",
        "\n",
        "        return np.random.rand(1)[0]\n",
        "\n",
        "    def compute_feature_b(image):\n",
        "        '''compute_feature_b will compute ...'''\n",
        "\n",
        "        return np.random.rand(1)[0]\n",
        "    \n",
        "    return compute_feature_a(image), compute_feature_b(image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KZUcGcnnah2i",
        "colab_type": "text"
      },
      "source": [
        "Once you compute these two features, you can apply them to your images. Don't worry about the details of the first function below, all it does is map the `compute_features` function you wrote to each image in your `X_train` variable.\n",
        "\n",
        "Afterwards let us plot the features you've crafted to see if they can separate into two classes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tSvyuJdZah2i",
        "colab_type": "code",
        "outputId": "c935b522-c583-45db-f04e-7537c1ea3b50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        }
      },
      "source": [
        "# Apply and plot your features (you can just run this block and inspect the output)\n",
        "\n",
        "X_features = np.apply_along_axis(compute_features, 1,\n",
        "                                 X_train.reshape(X_train.shape[0], X_train.shape[1]*X_train.shape[2]))\n",
        "\n",
        "X_features_a = X_features[np.where(y_train==number_a)]\n",
        "X_features_b = X_features[np.where(y_train==number_b)]\n",
        "\n",
        "plt.figure(figsize=(5,5))\n",
        "plt.plot(X_features_a[:, 0], X_features_a[:, 1], '.')\n",
        "plt.plot(X_features_b[:, 0], X_features_b[:, 1], '.')\n",
        "plt.xlabel('feature_a')\n",
        "plt.ylabel('feature_b')\n",
        "plt.ylim(X_features[:, 1].min(), X_features[:, 1].max()) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.009757423217968242, 0.9942443847003773)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAU4AAAFBCAYAAAAYBUa8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WOtC322Kah2m",
        "colab_type": "text"
      },
      "source": [
        "# 2. Linear Classification with Pseudo Inverse\n",
        "\n",
        "`X_features` is a 2 dimensional array of features and `y_train` is our ground truth label. Find the best plane that separates these two classes using the pseudo inverse and plot it. For this problem, as discussed in class, we set the labels as `y=-1` for `number_a` and `y=1` for `number_b`.\n",
        "\n",
        "The loss $L$ we would like to minimize for each $i$ row in our matrix is.\n",
        "\n",
        "$$L  = \\frac{1}{2}\\Sigma (y^{(i)} - W^{T}x^{(i)})^{2}$$\n",
        "\n",
        "where\n",
        "\n",
        "$$x^{(i)} = \n",
        "\\begin{bmatrix}\n",
        "    feature_a \\\\\n",
        "    feature_b \\\\\n",
        "\\end{bmatrix}$$\n",
        "\n",
        "$$W = \n",
        "\\begin{bmatrix}\n",
        "    w_1 \\\\\n",
        "    w_2 \\\\\n",
        "\\end{bmatrix}$$\n",
        "\n",
        "\n",
        "In matrix form we convert $x^{(i)}$ into $X$ which is the number of examples we have, in our case is MNIST digit features extracted.\n",
        "\n",
        "$$X = \n",
        "\\begin{bmatrix}\n",
        "    feature_{a1} & feature_{b1} \\\\\n",
        "    feature_{a2} & feature_{b2} \\\\\n",
        "    ... & ... \\\\\n",
        "    feature_{ai} & feature_{bi} \\\\\n",
        "\\end{bmatrix}$$\n",
        "\n",
        "\n",
        "$$L  = \\frac{1}{2}( Y-XW )^{T} (Y-XW)$$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bFCIv7Qaah2n",
        "colab_type": "text"
      },
      "source": [
        "### Explain\n",
        "\n",
        "Let's solve L analytically, by setting $\\frac{d}{dW}L = 0$ and solving for $W$, showing your steps along the way. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4nraJeeBah2p",
        "colab_type": "text"
      },
      "source": [
        "Step 1: $$L  = \\frac{1}{2}( Y-XW )^{T} (Y-XW)$$\n",
        "\n",
        "Step 2: $$ \\frac{d}{dW}L  = \\frac{d}{dW} \\frac{1}{2}( Y-XW )^{T} (Y-XW)$$\n",
        "\n",
        "Step 3: $$...$$\n",
        "\n",
        "(complete the remaining steps in markdown)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dkBTfoS3ah2q",
        "colab_type": "text"
      },
      "source": [
        "### Compute\n",
        "Going back to linear algebra, we can re-write the classification problem as $Xw = y^*$, as we did during class. Here, $X$ is our features matrix `X_features` that has the features of each data example along each row, $y^*$ is our `pseudo_y` vector, and $w$ is the unknown weights vector that we'd like to figure out.\n",
        "\n",
        "The pseudo inverse is $$(X^{T}X)^{-1}X^{T} = X^{+}$$\n",
        "\n",
        "Solving for $w$, $$w = X^{+}y^*$$\n",
        "\n",
        "To perform this computation: \n",
        "\n",
        "#### (a) create a features vector $X$ and compute its pseudo inverse. (This is the var `X_features`)\n",
        "\n",
        "#### (b) create a vector like $y^*$ to hold the labels. (Done below for you as `pseudo_y`)\n",
        "\n",
        "#### (c) find $w$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3gyGK8Wpah2r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pseudo_y = np.copy(y_train)\n",
        "pseudo_y[y_train == number_a] = -1\n",
        "pseudo_y[y_train == number_b] = 1\n",
        "\n",
        "# Calculate x below\n",
        "# ...\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rRX4MGoSah2v",
        "colab_type": "text"
      },
      "source": [
        "### (d) To examine the result of the least squares solution under this formulation, compute the train and test error using an appropriate threshold (i.e., 0). Does your trained model generalize well to the test data? \n",
        "\n",
        "Create a function called `accuracy_metrics` which does this."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Nqw4AaSah2w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def accuracy_metrics(features, label):\n",
        "    # features should be your X_features\n",
        "    # label should be the y^{i} label\n",
        "    \n",
        "    \n",
        "    return 0 # Return the % accuracy\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DAKH01L5ah2z",
        "colab_type": "text"
      },
      "source": [
        "### (e) Visualize the decision boundary corresponding to your chosen threshold using the provided `visualize_model` function.  \n",
        "\n",
        "The function `visualize_model` takes in features, labels, and your calculated weights and shows a matplotlib figure."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ae8MxoUWah2z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# just run this block\n",
        "def newline(weight):\n",
        "    # adapted from https://stackoverflow.com/questions/36470343/how-to-draw-a-line-with-matplotlib/36479941\n",
        "    if len(weight) == 2:\n",
        "        p1 = weight[0]\n",
        "        p2 = weight[1]\n",
        "        ax = plt.gca()\n",
        "        xmin, xmax = ax.get_xbound()\n",
        "        if(p2 == 0):\n",
        "            xmin = xmax = 0\n",
        "            ymin, ymax = ax.get_ybound()\n",
        "        else:\n",
        "            ymax = -p1/p2*(xmax)\n",
        "            ymin = -p1/p2*(xmin)\n",
        "        l = mlines.Line2D([xmin,xmax], [ymin,ymax], color = \"g\", label = \"Decision\")\n",
        "        ax.add_line(l)\n",
        "       \n",
        "    elif len(weight) == 3:\n",
        "        p1 = weight[0]\n",
        "        p2 = weight[1]\n",
        "        b = weight[2]\n",
        "        ax = plt.gca()\n",
        "        xmin, xmax = ax.get_xbound()\n",
        "        if(p2 == 0):\n",
        "            xmin = xmax = b/p1\n",
        "            ymin, ymax = ax.get_ybound()\n",
        "        else:\n",
        "            ymax = -p1/p2*(xmax) - b/p2\n",
        "            ymin = -p1/p2*(xmin) - b/p2\n",
        "        l = mlines.Line2D([xmin,xmax], [ymin,ymax], color = \"g\", label = \"Decision\")\n",
        "        ax.add_line(l)\n",
        "       \n",
        "    return l\n",
        "\n",
        "def visualize_model(features, labels, weights):\n",
        "    plt.figure(figsize=(5,5))\n",
        "    X_features_a = features[np.where(labels==-1)]\n",
        "    X_features_b = features[np.where(labels==1)]\n",
        "    plt.plot(X_features_a[:, 0], X_features_a[:, 1], '.', label = \"{}\".format(number_a))\n",
        "    plt.plot(X_features_b[:, 0], X_features_b[:, 1], '.', label = \"{}\".format(number_b))\n",
        "    plt.xlabel('feature_a')\n",
        "    plt.ylabel('feature_b')\n",
        "    plt.ylim(features[:, 1].min(), features[:, 1].max())\n",
        "    newline(weights)\n",
        "    plt.gca().legend(loc = 1)\n",
        "    return None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIikL7IWah23",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "visualize_model(X_features, pseudo_y, x)  # should output the datapoints with the decision boundary"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XAHm0fCaah26",
        "colab_type": "text"
      },
      "source": [
        "### (f) Repeat the above steps after adding in a bias term, allowing for the classification line to not pass through the origin. You can do this by augmenting the X feature matrix with an additional feature column of ones, and making the unknown weight vector one entry longer -- does performance improve?\n",
        "\n",
        "If you created your functions correctly, you shouldn't need to change them and you only need to modify `X_features`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMK9x0f9ah27",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Find w and bias\n",
        "\n",
        "# Get the test and train accuracy of your model with bias\n",
        "\n",
        "# Visualize the model, you may need to change your code."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fPhVLeWrah2-",
        "colab_type": "text"
      },
      "source": [
        "# 3. Linear Classification with Finite Differences\n",
        "\n",
        "Rather than use pseudo inverse (analytically solving your optimization equation). Instead, initialize your parameter x to some random numbers. Move x some small epsilon amount in the each direction to compute the total change in your loss and calculate the gradient. Then update x by taking a small step in that gradient direction. You can execute this in a for loop for a set number of iterations, or until the gradient reaches some threshold value of not changing very much.\n",
        "\n",
        "1. Solve for x\n",
        "2. Get training and test accuracy every $n$ steps\n",
        "3. Plot the decision boundary every $n$ steps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MYiFy7X7ah2_",
        "colab_type": "text"
      },
      "source": [
        "### Define a loss."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "njA28xScah2_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loss(features, labels, weights):\n",
        "    return np.inf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWPlrP_5ah3B",
        "colab_type": "text"
      },
      "source": [
        "### Now iteratively solve for your weights w, which includes the bias term."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4QH0FXr6ah3C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "w = np.random.rand(3) # init weights to some random value.\n",
        "num_iterations = 0 # set this to the number of iterations\n",
        "delta = 1e-4 # This may need to be adjusted\n",
        "step_size = 1e-4 # This may also need to be adjusted\n",
        "for i in range(num_iterations):\n",
        "    # move x0 some delta and calculate derivative in x0 direction\n",
        "    # move x1 some delta and calculate derivative in x1 direction\n",
        "    # update x0 and x1 some step_size in the direction of steepest descent"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfvD0at0ah3E",
        "colab_type": "text"
      },
      "source": [
        "# 4. Logistic Classification with Finite Differences\n",
        "\n",
        "Now, let's consider the same problem with a different loss function.\n",
        "\n",
        "$$L = \\frac{1}{N}\\sum_{i=1}^n ln(1 + e^{-y^{(i)}W^{T}x^{(i)}})$$\n",
        "\n",
        "Use finite differences to compute the gradient and iteratively calculate $W$\n",
        "\n",
        "1. Solve for x\n",
        "2. Get training and test accuracy every $n$ steps\n",
        "3. Plot the decision boundary every $n$ steps\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWosSFseah3E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "logistic_y = np.copy(y_train)\n",
        "logistic_y[y_train == number_a] = 0\n",
        "logistic_y[y_train == number_b] = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FH5yaFWKah3G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def logistic_loss(features, labels, weights, x, y):\n",
        "    return np.inf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJK8Fpybah3I",
        "colab_type": "text"
      },
      "source": [
        "# Part II\n",
        "\n",
        "In Parts II and III, we'll add some very small modifications to the above code that you just wrote, and will re-run it to examine how the performance changes. \n",
        "\n",
        "For Part II, let’s repeat the exercise above (Part I), but using a different set of features (you don't have to redo the pseudo-inverse derivation or anything like that - just change how you're defining the two features of interest in the associated fucntion). Here, let’s assume that we have a camera that has just two pixels in it, which is taking pictures of the MNIST image dataset. One of these two pixels will detect the total intensity from the top half of each digit to form feature x_1, and the other pixel will detect the total intensity from the bottom half of each digit to form feature x_2. Please use these two top/bottom total intensities to form a new feature vector for each MNIST image that you’re using for classification, and repeat the exercise above to obtain a plot of classification performance and an average classification accuracy score. \n",
        "\n",
        "**Note that this classification score (in some sense) reflects what would be possible with a \"normal\" camera.**\n",
        "\n",
        " - Plot Points after feature generation\n",
        " - Linear Classification (Pseudo or Gradient method)\n",
        "   - test/train accuracy\n",
        " - Logistic Classification\n",
        "   - test/train accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6FGm_WiTah3J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_features(vector):\n",
        "    image = vector.reshape(8, 8) # get back original image shape\n",
        "    def compute_feature_a(image):\n",
        "        '''compute_feature_a will compute ...'''\n",
        "\n",
        "        return np.random.rand(1)[0]\n",
        "\n",
        "    def compute_feature_b(image):\n",
        "        '''compute_feature_b will compute ...'''\n",
        "\n",
        "        return np.random.rand(1)[0]\n",
        "    \n",
        "    return compute_feature_a(image), compute_feature_b(image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ss9n3k_-ah3N",
        "colab_type": "text"
      },
      "source": [
        "# Part III\n",
        "\n",
        "Once again, in Part III, we'll add a very small modification to your code in Part II. Here, let’s assume that this camera has a special filter in its lens that blurs the MNIST image in a special way before it is detected. Let’s model this 2D blur as a convolution with the 3x3 filter below.\n",
        "\n",
        "$$X = \n",
        "\\begin{bmatrix}\n",
        "    -1 & 0 & 1 \\\\\n",
        "    -1 & 0 & 1 \\\\\n",
        "    -1 & 0 & 1 \\\\\n",
        "\\end{bmatrix}$$\n",
        "\n",
        "Convolve the set of MNIST images with this kernel before proceeding to compute the two features of interest as in Part I: the total image intensity, and the image symmetry. Repeat the exercise above to obtain a plot of classification performance and an average classification accuracy score.\n",
        "\n",
        "**Note that this classification score (in some sense) reflects what would be possible with a “computational” camera, which has a special aperture shape for enhanced image classification.**\n",
        "\n",
        " - Plot Points after feature generation\n",
        " - Linear Classification (Pseudo or Gradient method)\n",
        "   - test/train accuracy\n",
        " - Logistic Classification\n",
        "   - test/train accuracy"
      ]
    }
  ]
}
