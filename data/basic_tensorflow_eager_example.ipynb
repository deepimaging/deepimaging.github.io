{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "basic_tensorflow_eager_example.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1Ax7P0o-p7n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "tf.enable_eager_execution()  # if we're using tf version 1.14, then we need to call this command; if using 2.0, then eager execution is enabled by default"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0Gnqw_a_e51",
        "colab_type": "code",
        "outputId": "c24cdcac-70e0-4d72-a8cd-d63985c677c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "ooptimizer = tf.train.GradientDescentOptimizer(learning_rate=.2)  # choose our optimizer and learning rate\n",
        "x = tf.Variable(2.0)  # define a variable to optimize, with an initial value of 2\n",
        "\n",
        "for i in range(10):  # iterative optimization loop\n",
        "  with tf.GradientTape() as tape:  # gradient tape keeps track of the gradients associated with all the operations\n",
        "    # define our very simple minimization problem:\n",
        "    loss = x ** 2  # we're going to minimize x^2, which occurs at x=0\n",
        "\n",
        "    # compute and apply gradients:\n",
        "    gradient = tape.gradient(loss, x)\n",
        "    optimizer.apply_gradients([(gradient, x)])\n",
        "\n",
        "    # print out current iteration and loss value:\n",
        "    print(i, 'loss = ' + str(loss.numpy()), 'x = ' + str(x.numpy()))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 loss = 4.0 x = 1.2\n",
            "1 loss = 1.44 x = 0.72\n",
            "2 loss = 0.5184 x = 0.432\n",
            "3 loss = 0.186624 x = 0.2592\n",
            "4 loss = 0.06718464 x = 0.15552\n",
            "5 loss = 0.024186473 x = 0.093312\n",
            "6 loss = 0.008707129 x = 0.0559872\n",
            "7 loss = 0.0031345668 x = 0.03359232\n",
            "8 loss = 0.001128444 x = 0.020155393\n",
            "9 loss = 0.00040623985 x = 0.012093236\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RM1ZJzpCALju",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}