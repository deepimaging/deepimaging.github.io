{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "high_level_tf_intro.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AH2wp6LYAeph",
        "colab_type": "text"
      },
      "source": [
        "# Introduction to high-level tensorflow 2.0 using keras\n",
        "(adapted from https://www.tensorflow.org/tutorials/quickstart/beginner)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-uEbvk2_g7n",
        "colab_type": "code",
        "outputId": "7d02538c-1347-4942-a4cd-f1044863b0bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "# get tensorflow 2.0 (run once per session)\n",
        "pip install tensorflow==2.0"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow==2.0 in /usr/local/lib/python3.6/dist-packages (2.0.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (1.11.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (1.1.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.1.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (2.0.1)\n",
            "Requirement already satisfied: tensorboard<2.1.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (2.0.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (0.33.6)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (1.1.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (0.8.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (1.12.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (1.16.5)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (0.8.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (1.0.8)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (3.1.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (0.1.7)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (1.15.0)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (0.2.2)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (3.10.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (41.4.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (3.1.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (0.16.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==2.0) (2.8.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "982OTw7I_uxc",
        "colab_type": "code",
        "outputId": "37151fc9-51f7-444d-9cde-bf7504c6c05e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "print('tensorflow version: ' + tf.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensorflow version: 2.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IIYgWeQl_6SS",
        "colab_type": "code",
        "outputId": "5d5a3468-2489-42f6-b78b-66a35ad5d82d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "# load mnist dataset\n",
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0  # customary normalization to [0, 1]\n",
        "\n",
        "print(x_train.shape, y_train.shape)\n",
        "print(x_test.shape, y_test.shape)\n",
        "\n",
        "# Standard Scaling the data\n",
        "print('Train', x_train.min(), x_train.max(), x_train.mean(), x_train.std())\n",
        "print('Test', x_test.min(), x_test.max(), x_test.mean(), x_test.std())\n",
        "\n",
        "x_train = (x_train-x_train.mean())/x_train.std()\n",
        "x_test = (x_test-x_test.mean())/x_test.std()\n",
        "\n",
        "print('Train', x_train.min(), x_train.max(), x_train.mean(), x_train.std())\n",
        "print('Test', x_test.min(), x_test.max(), x_test.mean(), x_test.std())"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28) (60000,)\n",
            "(10000, 28, 28) (10000,)\n",
            "Train 0.0 1.0 0.1306604762738429 0.3081078038564622\n",
            "Test 0.0 1.0 0.13251460584233699 0.3104802479305348\n",
            "Train -0.4240738943915667 2.8215433456893395 -8.196738828119618e-17 1.000000000000001\n",
            "Test -0.4268052693386959 2.794011535161327 -2.251287591722145e-16 1.0000000000000004\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61LLcFDQE_j7",
        "colab_type": "text"
      },
      "source": [
        "## Simple, one-layer, fully-connected neural network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HtburEP7ADpc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define the sequential model (i.e., each layer follows sequentially from the previous)\n",
        "simple_model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=(28, 28)),  # fully-connected, so flatten the image\n",
        "    tf.keras.layers.Dense(units=128, activation='relu'),  # hidden layer has 128 units\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')  # length-10 output for classification\n",
        "])\n",
        "\n",
        "simple_model.compile(optimizer='adam',  # pick an optimizer\n",
        "                     loss='sparse_categorical_crossentropy',  # pick a loss\n",
        "                     metrics=['accuracy'])  # pick a metric to monitor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iehUiIj8AYMq",
        "colab_type": "code",
        "outputId": "8eb0c9d8-ca27-442e-c02f-86a3514b3125",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "# train model and track validation loss after each epoch:\n",
        "simple_model.fit(x_train, y_train,\n",
        "                 epochs=5,\n",
        "                 batch_size=32,\n",
        "                 validation_data=(x_test, y_test))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 7s 119us/sample - loss: 0.4046 - accuracy: 0.8764 - val_loss: 0.1649 - val_accuracy: 0.9485\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 6s 104us/sample - loss: 0.2406 - accuracy: 0.9267 - val_loss: 0.1262 - val_accuracy: 0.9622\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 6s 98us/sample - loss: 0.2123 - accuracy: 0.9365 - val_loss: 0.1146 - val_accuracy: 0.9649\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 6s 98us/sample - loss: 0.1924 - accuracy: 0.9415 - val_loss: 0.1033 - val_accuracy: 0.9691\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 6s 103us/sample - loss: 0.1780 - accuracy: 0.9448 - val_loss: 0.1093 - val_accuracy: 0.9685\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f6665fe4dd8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "racYUsrvBzZV",
        "colab_type": "code",
        "outputId": "9e8bcd0f-a191-4f22-d21a-a52957701bb9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        }
      },
      "source": [
        "# let's examine some sample predictions:\n",
        "prediction = simple_model.predict_classes(x_test)\n",
        "\n",
        "# incorrect predictions:\n",
        "incorrect = prediction != y_test\n",
        "incorrect_indices = np.where(incorrect)[0]\n",
        "print('error rate = ' + str(np.mean(incorrect)))  # should be 1 - val_accuracy\n",
        "print('These are the indices corresponding to the test samples that our model got wrong:')\n",
        "print(incorrect_indices)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "error rate = 0.0315\n",
            "These are the indices corresponding to the test samples that our model got wrong:\n",
            "[   8  149  151  233  241  247  259  300  320  321  362  381  412  445\n",
            "  448  449  478  479  495  551  582  619  646  659  684  691  707  720\n",
            "  726  740  839  844  881  924  956  965  982 1003 1014 1044 1107 1112\n",
            " 1181 1206 1226 1228 1232 1247 1260 1283 1319 1326 1364 1393 1414 1469\n",
            " 1494 1500 1522 1527 1530 1549 1553 1569 1609 1681 1709 1717 1737 1751\n",
            " 1754 1790 1800 1850 1878 1901 1952 1970 2004 2016 2035 2040 2043 2044\n",
            " 2053 2068 2093 2098 2109 2118 2129 2130 2135 2182 2186 2189 2224 2237\n",
            " 2266 2272 2293 2299 2325 2369 2380 2387 2393 2406 2414 2433 2462 2488\n",
            " 2578 2598 2607 2648 2654 2730 2760 2810 2877 2896 2921 2927 2939 2953\n",
            " 3005 3030 3060 3073 3100 3117 3206 3225 3240 3289 3329 3330 3336 3405\n",
            " 3422 3490 3503 3520 3549 3558 3559 3565 3567 3597 3604 3629 3662 3674\n",
            " 3716 3751 3767 3776 3780 3808 3811 3817 3821 3838 3853 3869 3893 3906\n",
            " 3926 3941 3968 3976 3985 4007 4065 4078 4163 4176 4201 4224 4228 4238\n",
            " 4256 4265 4271 4289 4306 4355 4369 4374 4433 4443 4497 4500 4567 4571\n",
            " 4578 4601 4635 4690 4731 4740 4751 4807 4814 4823 4837 4874 4879 4880\n",
            " 4886 4956 4966 4978 4990 5067 5068 5140 5159 5331 5409 5457 5495 5600\n",
            " 5617 5642 5734 5749 5835 5842 5887 5926 5936 5937 5955 5972 5973 5975\n",
            " 6024 6059 6071 6081 6091 6166 6168 6172 6421 6505 6555 6560 6568 6571\n",
            " 6577 6597 6625 6632 6651 6740 6744 6755 7208 7248 7338 7432 7434 7797\n",
            " 7800 7812 7821 7849 7886 7899 7990 8020 8062 8081 8094 8095 8183 8316\n",
            " 8325 8339 8520 8522 8527 9008 9009 9015 9019 9024 9036 9071 9280 9587\n",
            " 9634 9642 9669 9679 9698 9700 9729 9732 9741 9745 9749 9755 9768 9770\n",
            " 9779 9792 9808 9839 9888 9941 9982]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qlfspfFFZZy",
        "colab_type": "code",
        "outputId": "776d6101-c8f1-426c-d5f7-d3c5553aa8f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        }
      },
      "source": [
        "# plot 5 examples of wrong classifications:\n",
        "plt.figure(figsize=(20, 5))\n",
        "for i, i_wrong in enumerate(incorrect_indices[:5]):\n",
        "  plt.subplot(1, 5, i + 1)\n",
        "  plt.imshow(x_test[i_wrong], cmap='gray')\n",
        "  plt.title('Prediction: ' + str(prediction[i_wrong]) + ', Truth: ' + str(y_test[i_wrong]))\n",
        "  plt.axis('off')\n",
        "plt.show()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABH4AAADvCAYAAACEwBPsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAANJTGDwAAAEBDafwAAAAANNT/B/fo/UyhnWdkAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 1440x360 with 5 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvdNOITtIML3",
        "colab_type": "text"
      },
      "source": [
        "## Convolutional neural network example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9benkxclJPn6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# because we're using CNNs, the data needs a channel dimension:\n",
        "x_train = x_train[..., None]\n",
        "x_test = x_test[..., None]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1fczsbMgHNCS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cnn_model = tf.keras.models.Sequential([\n",
        "    # let's add some convolutional layers:\n",
        "    tf.keras.layers.Conv2D(filters=32, kernel_size=3, strides=1, padding='same', activation='relu'),\n",
        "    tf.keras.layers.Conv2D(filters=32, kernel_size=3, strides=2, padding='same', activation='relu'),\n",
        "    # now, let's transition into a fully-connected layer; first, we flatten:\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(units=64, activation='relu'),\n",
        "    #tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')  # length-10 output for classification\n",
        "])\n",
        "\n",
        "cnn_model.compile(optimizer='adam',  # pick an optimizer\n",
        "                     loss='sparse_categorical_crossentropy',  # pick a loss\n",
        "                     metrics=['accuracy'])  # pick a metric to monitor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ijRtGnrI51V",
        "colab_type": "code",
        "outputId": "590c30ef-f75c-41d6-d240-67b2e78796df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "# train model and track validation loss after each epoch:\n",
        "cnn_model.fit(x_train, y_train,\n",
        "              epochs=2,\n",
        "              batch_size=32,\n",
        "              validation_data=(x_test, y_test))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/2\n",
            "60000/60000 [==============================] - 64s 1ms/sample - loss: 0.1334 - accuracy: 0.9592 - val_loss: 0.0520 - val_accuracy: 0.9832\n",
            "Epoch 2/2\n",
            "60000/60000 [==============================] - 64s 1ms/sample - loss: 0.0433 - accuracy: 0.9863 - val_loss: 0.0453 - val_accuracy: 0.9849\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f6663fa2ac8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6AUsJf_5I-u1",
        "colab_type": "code",
        "outputId": "03a7bcb6-0197-4bb8-acbe-a9781ded0007",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "cnn_model.summary()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              multiple                  320       \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            multiple                  9248      \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          multiple                  0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              multiple                  401472    \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              multiple                  650       \n",
            "=================================================================\n",
            "Total params: 411,690\n",
            "Trainable params: 411,690\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJzBEt3QVUxz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}