{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "phIROnd7F_JQ",
        "outputId": "85f0449a-480c-4088-cee8-a9b681be824e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# customary imports:\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image, ImageOps\n",
        "import glob\n",
        "import os\n",
        "import tqdm\n",
        "from sklearn.model_selection import StratifiedKFold"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensorflow version: 2.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fNv61VDIHDgb"
      },
      "source": [
        "## 1. Download the white blood cell classification data\n",
        "The data is hosted online, so we can use the linux command `wget` to download it. If you run into any issues with the data download, please just share your challenges via Slack and we can help sort them out."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZYusjuPNtTmE"
      },
      "source": [
        "# if this breaks please contact the TAs\n",
        "!wget -O data.zip https://data.mendeley.com/public-files/datasets/snkd93bnjr/files/2fc38728-2ae7-4a62-a857-032af82334c3/file_downloaded\n",
        "!unzip /content/data.zip\n",
        "!unzip /content/PBC_dataset_normal_DIB.zip > /dev/null"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72pPlR8-teIU"
      },
      "source": [
        "# loading a sample image\n",
        "sample_image = Image.open(\"PBC_dataset_normal_DIB/basophil/BA_100102.jpg\")\n",
        "sample_image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4LB0cdDHBrQ"
      },
      "source": [
        "def load_and_crop(image_path, crop_size, normalized=True):\n",
        "    image = Image.open(image_path).resize([200,200])\n",
        "    width, height = image.size   # Get dimensions\n",
        "    left = (width - crop_size)/2\n",
        "    top = (height - crop_size)/2\n",
        "    right = (width + crop_size)/2\n",
        "    bottom = (height + crop_size)/2\n",
        "    # Crop the center of the image\n",
        "    image = ImageOps.grayscale(image.crop((left, top, right, bottom)))\n",
        "    if normalized:\n",
        "        return np.array(image).astype(np.float32) / 255.0\n",
        "    else:\n",
        "        return np.array(image).astype(np.float32)\n",
        "\n",
        "# code to load all the data, assuming dataset is at PBC_dataset_normal_DIB relative path\n",
        "cell_types = ['basophil', 'eosinophil', 'erthroblast', 'ig', 'lymphocyte', 'monocyte', 'neutrophil', 'platelet']\n",
        "cell_inds = np.arange(0, len(cell_types))\n",
        "x_data = []\n",
        "y_data = []\n",
        "for cell_ind in cell_inds:\n",
        "    all_images = glob.glob(os.path.join('PBC_dataset_normal_DIB', cell_types[cell_ind], '*.jpg'))\n",
        "    x_data += [load_and_crop(image_path, 128) for image_path in all_images]\n",
        "    y_data += [cell_ind]*len(all_images)\n",
        "\n",
        "# adding a fake color channel\n",
        "x_data = np.array(x_data).reshape(-1, 128, 128, 1)\n",
        "y_data = np.array(y_data)\n",
        "\n",
        "folder = StratifiedKFold(5, shuffle=True)\n",
        "x_indices = np.arange(0, len(x_data))\n",
        "train_indices, val_indices = folder.split(x_indices, y_data).__next__()\n",
        "# shuffling\n",
        "np.random.shuffle(train_indices)\n",
        "\n",
        "x_train = x_data[train_indices]\n",
        "y_train = np.eye(len(cell_types))[y_data[train_indices]]\n",
        "\n",
        "x_val = x_data[val_indices]\n",
        "y_val = np.eye(len(cell_types))[y_data[val_indices]]\n",
        "\n",
        "print(x_train.shape, y_train.shape)\n",
        "print(x_val.shape, y_val.shape)\n",
        "\n",
        "plt.imshow(x_train[0,:,:,0])\n",
        "plt.colorbar()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kBvySu7UqbhC"
      },
      "source": [
        "## 2. Define a keras model\n",
        "You can either use the sequential model class, or the functional model declaration\n",
        "\n",
        "(a) Please define your model with the following layers:\n",
        "1. A convolutional layer with a 5x5 kernel and stride of 1\n",
        "2. A convolutional layer with a 5x5 kernel and stride of 1\n",
        "3. A pooling layer (Instead of this, you could also increase the stride in the second layer)\n",
        "4. A convolutional layer with a 5x5 kernel and stride of 1\n",
        "5. A convolutional layer with a 5x5 kernel and stride of 1\n",
        "6. A pooling layer (Instead of this, you could also increase the stride in the fifth layer)\n",
        "7. A Dense layer\n",
        "8. Output layer of size 8\n",
        "\n",
        "You are free to choose the sizes, number of channels and activations (i.e., the employed non-linearity) for each of the layers.\n",
        "\n",
        "(b) Now, please comment out the pooling layer in step 3 and step 6, and instead increase the stride in the appropriate layers to achieve the same down-sampling effect (i.e., to reduce the size of the tensor in the same way as pooling) \n",
        "\n",
        "(c) After defining the model, you should define an optimizer and set a learning rate. You also should pick a loss function.\n",
        "\n",
        "(d) Run the optimization for 10-15 epochs and monitor the training and validation loss and accuracy. After training is done, please plot two graphs, one showing the training and validation losses as two curves within the same plot, and a second graph that shows the the training and validation accuracies as two curves within the same plot. For both plots, please let epoch be the horizontal axis.\n",
        "\n",
        "At the end of training, you should be able obtain an accuracy better than 80%.\n",
        "\n",
        "You may refer to the notebook from the TA session or any online TensorFlow resources for guidance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UdaCeAafKfBH"
      },
      "source": [
        "# your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5t_4Q3Zpcbm"
      },
      "source": [
        "## 3. How many weight parameters does your network have?\n",
        "First try calculating this number by hand, and show your work (please type out the multiplications that you are performing to arrive at the final number.) Then, please verify the answer using Keras's autogenerated model summary."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iAGKahMOtgq2"
      },
      "source": [
        "## 4. Visualise filters\n",
        "You can obtain weights in individual layers by running \n",
        "```\n",
        "your_model_variable.layers[layer_index].get_weights()\n",
        "```\n",
        "(a) Plot all convolution kernels (i.e., each set of 5x5 weights) in your first convolutional layer.\n",
        "\n",
        "(b) What is the variance of final weights in the first convolutional layer? \n",
        "\n",
        "(c) Also plot some of the convolutional weights in the second layer. What is the variance of the final weights in the second layer? \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJmhDicQKlga"
      },
      "source": [
        "# your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WIzRfmIkq-A0"
      },
      "source": [
        "## 5. Try playing with the learning rate\n",
        "(a) Try to increase and decrease the learning rate and plot the training and validation loss and accuracy curves from part 2(d), for three different values of learning rate that you have tried. \n",
        "\n",
        "(b) Please comment on any trends that you can identify between how the plots change as a function of learning rate. Specifically, what happens to the slopes of the training loss and accuracy as a function of learning rate?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5DDZbZ58KpSQ"
      },
      "source": [
        "# your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d16axQgDqZEk"
      },
      "source": [
        "## 6. Adding Batch Norm\n",
        "Fix a value of the learning rate and try adding Batch Normalization after layers 2 and 5. Does it improve the performance of your model? Explain briefly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8LDjTalKsQj"
      },
      "source": [
        "# your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "se4HHIwzuM6l"
      },
      "source": [
        "## 7. Data Augmetation\n",
        "Now, instead of giving the dataset directly to the network, augment it first using:\n",
        "```\n",
        "keras.preprocessing.image.ImageDataGenerator\n",
        "```\n",
        "Specifically, use vertical and horizontal flips and 20 degrees rotation. We also want to normalise the data. Feel free to consult the documentation for this function.\n",
        "What effect does this have on your model?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GbnA3Wd_KvCa"
      },
      "source": [
        "# your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6RujmNUTRmAG"
      },
      "source": [
        "## 8. Custom layers\n",
        "In one of the TA sessions, we briefly went over how to implement a custom layer -- specifically, we re-implemented the Dense (or fully-connected) layer. In this part, we will get more practice implementing custom layers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RjUYKqSjsD_C"
      },
      "source": [
        "Please reimplement a simplified version of `tf.keras.layers.Conv2D` using `tf.nn.conv2d`: https://www.tensorflow.org/api_docs/python/tf/nn/conv2d\n",
        "\n",
        "Note carefully the difference between these two tf constructs. In particular, `tf.keras.layers.Conv2D` is a high-level implementation of the 2D convolution that defines all the parameters under the hood, while `tf.nn.conv2d` requires you to define your own convolutional kernels via `tf.Variable` (you may also use the `add_weight` function if you desire). \n",
        "- Your implementation should also include a bias variable, consistent with the default behavior of `tf.keras.layers.Conv2D`.\n",
        "- Your constructor should accept 4 parameters: filters, kernel_size, strides, and activation.\n",
        "- You may hard-code the padding as `'SAME'`\n",
        "- You do not have to implement the string shortcuts for the activations (e.g., if your code handles `tf.nn.relu` but not `'relu'`, that's okay).\n",
        "- For simplicity, you may assume that kernel_size and strides are integers (i.e., as opposed to lists).\n",
        "- Initialize all weights using the standard normal distribution.\n",
        "\n",
        "Note that since you only have to deal with the above 5 input arguments, your implementation will not be as sophisticated as `tf.keras.layers.Conv2D`, which contains many other input arguments. Rather, the point of this exercise is for you to get a better understanding of what tf is doing under the hood so that you are not just blindly using their high-level functions.\n",
        "\n",
        "Feel free to refer to the notebook from the TA session or any online tf documentation, though please do not copy the source code from tf's native implementation of Conv2D.\n",
        "\n",
        "After you're done, repeat the CNN defined above, substituting all instances of `tf.keras.layers.Conv2D` with your implementation, and run for 10 epochs. It's okay if you don't get the same accuracy, but it should still improve. Also print out the `.summary()` command to ensure that the number of parameters is the same as before."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vxp2tYd8RndZ"
      },
      "source": [
        "class Conv2D(tf.keras.layers.Layer):\n",
        "  def __init__(self, filters, kernel_size, strides, activation):\n",
        "    super().__init__()\n",
        "    pass\n",
        "  \n",
        "  def build(self, input_shape):\n",
        "    # expect the input_shape to be (batch_size, height, width, filters_previous)\n",
        "    pass\n",
        "  \n",
        "  def call(self, input):\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-16TCZxsS6o"
      },
      "source": [
        "# copy and paste an earlier training script, and replace the native conv2Ds with yours"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pWn7tWEir2Du"
      },
      "source": [
        "##** Bonus question: Custom layer for Fourier filtering\n",
        "\n",
        "Note: this problem requires some careful bug-checking"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FVL9zoNPzaln"
      },
      "source": [
        "Now, we will implement a custom layer that doesn't exist in keras -- Fourier filtering. Your layer should apply the 2D Fourier transform (`tf.signal.fft2d`) to each channel of the input, multiply element-wise by an optimizable mask (a different one for each channel), apply the 2D inverse Fourier transform (`tf.signal.ifft2d`), and then take the absolute value. Note: \n",
        "- You will have to use the tf versions of all operations, NOT the numpy versions. \n",
        "- The fft2d operations in tensorflow are done on the LAST two dimensions, which is at odds with the default dimension ordering of CNNs. Thus, you will need to use `tf.transpose` on the input and then transpose back after the filtering operation.\n",
        "- Use dtype `tf.complex64`, which is basically a combination of two `tf.float32`s. You will have to explicitly cast between these two data types, because the input/output will be `tf.float32`, but intermediate steps will be `tf.complex64`.\n",
        "\n",
        "Initialize your optimizable Fourier masks using a binary circular mask (1's inside the circle, 0's outside), with a radius given by 1/4 of the square image dimension (you can round if not divisible by 4). \n",
        "\n",
        "After defining this custom layer, copy your previously defined CNN above and insert this new layer as the first layer. To verify that your layer is working correctly, plot some example outputs of the first layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kmqnrPjs0LcC"
      },
      "source": [
        "class FourierFilter(tf.keras.layers.Layer):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "  \n",
        "  def build(self, input_shape):\n",
        "    # expect the input_shape to be (batch_size, height, width, filters_previous)\n",
        "    pass\n",
        "  \n",
        "  def call(self, input):\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_T42rvrwaz5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "HW3_2020F.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}