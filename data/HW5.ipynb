{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "HW5.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOJ_yoKrfRTY"
      },
      "source": [
        "# HW5 (Last homework): designing a microscope using machine learning\n",
        "\n",
        "For the final homework assignment, we will design a microscope using machine learning! In order to do this, we will combine elements of HW3 (CNNs) and HW4 (microscope simulator) into a single end-to-end architecture. In particular, we will convert the white blood cell images into phase/amplitude objects, and then process them through a microscope simulator as we did in HW4, add noise, and then feed the resulting images into a CNN for classification. In addition to optimizing the CNN parameters, we will also be simultaneously optimizing the input illumination incident on the phase/amplitude objects, as well as the shape of the microscope's aperture, to try to improve classification performance.\n",
        "\n",
        "Below, we will walk you through the steps of implementing this joint architecture, leaving some portions blank for you to implement. We will first instruct you to use specific values that we have tested and are known to give reasonable results. Later on, you will revisit the code and explore different hyperparameter settings.\n",
        "\n",
        "Some code adapted from https://www.tensorflow.org/tutorials/quickstart/advanced\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYnxhSX2fRTa"
      },
      "source": [
        "## 1. import stuff and load the dataset\n",
        "As always, we split the dataset into training and testing. You can just run this code, you don't need to understand what's going on"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A7HCC0rr2A1h"
      },
      "source": [
        "# if this breaks please contact the TAs\n",
        "!wget -O data.zip https://data.mendeley.com/public-files/datasets/snkd93bnjr/files/2fc38728-2ae7-4a62-a857-032af82334c3/file_downloaded\n",
        "!unzip /content/data.zip\n",
        "!unzip /content/PBC_dataset_normal_DIB.zip > /dev/null"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cxzcMNqk2CJu"
      },
      "source": [
        "# customary imports:\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image, ImageOps\n",
        "import glob\n",
        "import os\n",
        "import tqdm\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "def load_and_crop(image_path, crop_size, normalized=False):\n",
        "    image = Image.open(image_path).resize([200,200])\n",
        "    width, height = image.size   # Get dimensions\n",
        "    left = (width - crop_size)/2\n",
        "    top = (height - crop_size)/2\n",
        "    right = (width + crop_size)/2\n",
        "    bottom = (height + crop_size)/2\n",
        "    # Crop the center of the image\n",
        "    image = ImageOps.grayscale(image.crop((left, top, right, bottom)))\n",
        "    if normalized:\n",
        "        return np.array(image).astype(np.float32) / 255.0\n",
        "    else:\n",
        "        return np.array(image).astype(np.float32)\n",
        "\n",
        "# code to load all the data, assuming dataset is at PBC_dataset_normal_DIB relative path\n",
        "cell_types = ['basophil', 'eosinophil', 'erthroblast', 'ig', 'lymphocyte', 'monocyte', 'neutrophil', 'platelet']\n",
        "cell_inds = np.arange(0, len(cell_types))\n",
        "x_data = []\n",
        "y_data = []\n",
        "for cell_ind in cell_inds:\n",
        "    all_images = glob.glob(os.path.join('PBC_dataset_normal_DIB', cell_types[cell_ind], '*.jpg'))\n",
        "    x_data += [load_and_crop(image_path, 64) for image_path in all_images]\n",
        "    y_data += [cell_ind]*len(all_images)\n",
        "\n",
        "# adding a fake color channel\n",
        "folder = StratifiedKFold(5, shuffle=True)\n",
        "x_indices = np.arange(0, len(x_data))\n",
        "train_indices, val_indices = folder.split(x_indices, y_data).__next__()\n",
        "# shuffling\n",
        "np.random.shuffle(train_indices)\n",
        "\n",
        "x_data = np.array(x_data)\n",
        "y_data = np.array(y_data)\n",
        "\n",
        "x_train = x_data[train_indices]\n",
        "y_train = np.eye(len(cell_types))[y_data[train_indices]]\n",
        "\n",
        "x_val = x_data[val_indices]\n",
        "y_val = np.eye(len(cell_types))[y_data[val_indices]]\n",
        "\n",
        "print(x_train.shape, y_train.shape)\n",
        "print(x_val.shape, y_val.shape)\n",
        "\n",
        "plt.imshow(x_train[0,:,:])\n",
        "plt.colorbar()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "477WSWKPhc21"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "x_test = x_val\n",
        "y_test = y_val\n",
        "y_test = np.argmax(y_test, axis=-1)\n",
        "y_train = np.argmax(y_train, axis=-1)\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0  # customary normalization to [0, 1]\n",
        "\n",
        "print(x_train.shape, y_train.shape)\n",
        "print(x_test.shape, y_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YPDSXQihfRTd"
      },
      "source": [
        "## 2. convert the images into microscope samples\n",
        "Convert the images into phase-only objects. To do this, normalize the images to be between 0 and 1 (which was done above), and make the object 1 wavelength thick (we may come back later to adjust the sample thickness). We'll assume the wavelength of the light in this microscope is 500 nm, or 0.5 Âµm."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLHkiBdyfRTe"
      },
      "source": [
        "wavelength = .5\n",
        "def convert_images(X):\n",
        "    # your code here\n",
        "    pass\n",
        "\n",
        "x_train = convert_images(x_train)\n",
        "x_test = convert_images(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bUPwYeNQfRTg"
      },
      "source": [
        "## 3. create input pipeline for generating training/testing batches\n",
        "This code creates an object that you can iterate over to get image-label pairs. One is for the training set, the other is for the test set. You can just run this block."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VqM_NU1efRTg"
      },
      "source": [
        "train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(10000).batch(32)\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLyCH5NAfRTi"
      },
      "source": [
        "## 4. Define variables for physical layer\n",
        "First, we will create complex-valued trainable illumination wave. As described in class, this input illumination field can be represented by a complex-valued 2D matrix, which here will have 64x64 complex-valued entries that interact with each sample of a similar size. In practice, this input field might be obtained by using a spatial light modulator (SLM), an optical element that can be programmed to display an arbitrary phase and/or amplitude pattern pixel by pixel. We will use a phase-only SLM, so that the variable to optimize is a 64x64 array of phases (from 0 to 2pi)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6DuRpxxfRTi"
      },
      "source": [
        "# create the tf variable corresponding to the input illumination phase; initialize to a constant phase:\n",
        "# (remember this is a weight variable that you will optimize!)\n",
        "input_illumination_phase = None\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5sSudeTTOpcV"
      },
      "source": [
        "Next, we create a complex-valued trainable aperture function. In HW4, we modeled the aperture plane of the microscope using a circular function that was 1 inside the circle (100% transparent) and 0 outside the circle (0% transparent). Please do the same here. For now, in whatever coordinate system you have established, please try to ensure that the radius extends across 19 pixels of the 64 pixels that will define the k-space matrix for this dataset along one dimension. We may come back later to adjust this radius.\n",
        "\n",
        "In addition, for extra flexibility, let's add an SLM in the aperture plane. Assume the SLM is a phase-only SLM (only values from 0 to 2pi are allowed)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMmo8_u1On0q"
      },
      "source": [
        "# the aperture function consists of two parts: 1) the circular aperture as in HW4, and 2) a trainable 64x64 phase array\n",
        "# create a circular aperture as you did in HW4:\n",
        "circ_aper = None\n",
        "\n",
        "# create the variable corresponding to the aperture phase; initialize to a constant phase:\n",
        "# (remember this is a weight variable that you will optimize!)\n",
        "aperture_phase = None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hH8lGwqffRTk"
      },
      "source": [
        "## 5. Generate prediction from the physical layer.\n",
        "Write the physical layer as a function that will be used later. This will follow closely to what you did in HW4, except now all operations must be done with tensorflow operations, for example `tf.signal.fft2d`, `tf.signal.ifft2d`, and `tf.exp`. Note that while often numpy will cast between different data types, tensorflow in general will not, so you will have to use `tf.cast` to go between `tf.float32` and `tf.complex64`. Follow the comments below, which tell you what statements you have to write.\n",
        "\n",
        "Hint: we recommend subtracting out 1 from simulated noisy images, as we found that it promotes convergence speed. This is possibly because the magnitudes of our simulated phase-only images are close to 1, so the -1 centers the images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LpfI9mxCfRTk"
      },
      "source": [
        "def physical_layer(x_batch):\n",
        "  # x_batch is a batch of phase-only objects that we created earlier;\n",
        "  # propagate the field emerging from these objects to the Fourier plane, apply\n",
        "  # your aperture mask (circular aperture and phase), then propagate it to the\n",
        "  # image plane;\n",
        "\n",
        "  # add some gaussian noise with stdev of 0.2, to simulate detector noise:\n",
        "  noise_sig = .2\n",
        "  image += None\n",
        "\n",
        "  # if you didn't already, add color channel singleton dimension in preparation\n",
        "  # for processing through a CNN:\n",
        "  image = image[..., tf.newaxis]\n",
        "\n",
        "  return image-1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9q6yPj7nfRTs"
      },
      "source": [
        "## 6. process the simulated image through a CNN\n",
        "Use your favorite CNN architecture that classifies MNIST or come up with a new one. You may copy a network architecture from a previous TA or class session."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7SgA7uwffRTt"
      },
      "source": [
        "class CNN(tf.keras.Model):\n",
        "  def __init__(self):\n",
        "    super(CNN, self).__init__()\n",
        "    # ...\n",
        "  def call(self, x):\n",
        "    # ...\n",
        "\n",
        "model = CNN()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vA8aZ6Dgs6d"
      },
      "source": [
        "# the full forward model, which includes both the physical layer and the CNN model:\n",
        "def forward_model(x_batch):\n",
        "  p_layer_out = physical_layer(x_batch)\n",
        "  return model(p_layer_out)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aualWgvXfRTu"
      },
      "source": [
        "## 7. train!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ri4jgtxffRTw"
      },
      "source": [
        "Let's first look at a few simulated noisy microscope images before training. If your code is correct, the images should be essentially unrecognizable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "zPpL25ksfRTx"
      },
      "source": [
        "def plot_examples(batch):\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    for i in range(25):\n",
        "        plt.subplot(5, 5, i+1)\n",
        "        plt.imshow(batch[i, :, :, 0])\n",
        "        plt.colorbar()\n",
        "        plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "plot_examples(physical_layer(x_train[:25]).numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "INRuxIWzfRTz"
      },
      "source": [
        "Write your train loop here, using `tf.GradientTape()` to track the gradients. The variables you have to update are the CNN variables and the two phase matrices that we defined above. Feel free to monitor loss and/or aperture/illumination phases during training. Pick a value for the number of iterations and keep it fixed (run for at least one epoch). Don't forget to monitor test accuracy.\n",
        "\n",
        "You may find this link useful https://www.tensorflow.org/tutorials/quickstart/advanced."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DV_tqbjh0Mwj"
      },
      "source": [
        "# train loop\n",
        "# ..."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pWQUrmZcfRT1"
      },
      "source": [
        "Let's first look at a few simulated noisy microscope images AFTER training. Do the images look more recognizable?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0GoOifQfRT1"
      },
      "source": [
        "# plot examples \n",
        "plot_examples(physical_layer(x_train[:25]).numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-SL2HY7fRT5"
      },
      "source": [
        "## Questions\n",
        "\n",
        "Ok, now you've run a machine learning model with a physical layer! You did it! To complete the remainder of the homework, please follow the instructions for each question below, and then respond accordingly with the requested information. If it is helpful, please also copy and paste any major code changes into the question response, to help us assess what you did. Note that this is a pretty open-ended analysis, and everyone may achieve different results depending on the selected parameters -- as long as you get question 1 to work, it's okay if the other questions give uninteresting results!\n",
        "\n",
        "1. First, using the default hyperparameters based on the instructions and code that we provided, and please run the training under the following conditions:\n",
        "\n",
        "    a. Allow for the optimization of the complex-valued aperture mask (i.e., the 'aperture phase' variable) and the complex-valued  illumination field that illuminates the sample.\n",
        "\n",
        "    b. Allow for the optimization of neither the complex-valued aperture mask (i.e., the 'aperture phase' variable) nor the illumination field. Note that this is a control experiment, because only the CNN is trained, and not the physical layers.\n",
        "\n",
        "    c. Allow for the optimization of only the complex-valued aperture mask (i.e., the 'aperture phase' variable).\n",
        "\n",
        "    d. Allowing optimization of only the illumination field that illuminates the sample.\n",
        "    \n",
        "    For these 4 conditions, report the final test classification accuracies as well as the optimized aperture phase and/or illumination phase. Provide a brief analysis of the results (hint: if you don't see a difference between at least two of the above conditions, something probably went wrong!).\n",
        "   \n",
        "2. If you got question 1 to work, good work! Next, let's try changing some of the hyperparameters above. For each of the following questions, rerun the analysis from question 1 under conditions of 1(a) and 1(b).\n",
        "\n",
        "    a. Try decreasing the amount of noise added at the last step of the physical layer, for example to half and a quarter of the initial value. Try at least two values. Comment on the gap in performance between the physically-optimized and non-physically-optimized cases.\n",
        "\n",
        "    b. For question 1, you initialized with a constant phase. Next, try to initialize the optimization with random-valued aperture phase and illumination phase. Please report the resulting accuracy and optimized aperture phase and illumination phase.\n",
        "    \n",
        "    c. Try changing the diameter of the aperture to two other values. For example, half and double the original diameter used above. Please report the resulting accuracy both with and without the physical layer. "
      ]
    }
  ]
}
