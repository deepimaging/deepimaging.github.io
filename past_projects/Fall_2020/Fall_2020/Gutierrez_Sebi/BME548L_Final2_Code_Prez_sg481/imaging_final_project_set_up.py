# -*- coding: utf-8 -*-
"""Imaging Final Project_Set_Up.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1OC_57OUf1QhcUeEHy6zfuG-CVqmCbB4q
"""

import torch
import numpy as np
import urllib.request
import matplotlib.pyplot as plt
import torch
import torch.utils.model_zoo
from PIL import Image, ImageOps
import skimage.io as io
from skimage.draw import circle
import tensorflow as tf

! git clone https://github.com/ostadabbas/Infant-Pose-Estimation

pip install -r /content/Infant-Pose-Estimation/requirements.txt

!git clone https://github.com/waleedka/coco
!pip install -U setuptools
!pip install -U wheel
!make install -C coco/PythonAPI

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/Infant-Pose-Estimation/lib
!make

with open('/content/download.txt', 'w') as writefile:
  stable_url = "https://coe.northeastern.edu/Research/AClab/SyRIP/images/train_infant/train"
  for i in np.arange(1,501):
    num = i
    num1 = ("{:05d}".format(num))
    url=stable_url+str(num1)+".jpg"+"\n"
    writefile.write(url)
  for i in np.arange(10001,10505): 
    num = i
    num1 = ("{:05d}".format(num))
    url=stable_url+str(num1)+".jpg"+"\n"
    writefile.write(url)

# Commented out IPython magic to ensure Python compatibility.
# %%capture
# !wget -i /content/download.txt -P /content/Infant-Pose-Estimation/data/coco/images/train_infant

with open('/content/download2.txt', 'w') as writefile:
  stable_url = "https://coe.northeastern.edu/Research/AClab/SyRIP/images/validate_infant/test"
  for i in np.arange(0,10):
    num = i
    num1 = ("{:01d}".format(num))
    url=stable_url+str(num1)+".jpg"+"\n"
    writefile.write(url)
  for i in np.arange(10,100):
    num = i
    num1 = ("{:02d}".format(num))
    url=stable_url+str(num1)+".jpg"+"\n"
    writefile.write(url)

# Commented out IPython magic to ensure Python compatibility.
# %%capture
# !wget -i /content/download2.txt -P /content/Infant-Pose-Estimation/data/coco/images/validate_infant

# Commented out IPython magic to ensure Python compatibility.
# %%capture
# !wget -i https://coe.northeastern.edu/Research/AClab/SyRIP/annotations/val100/person_keypoints_validate_infant.json -P /content/Infant-Pose-Estimation/data/coco/annotations
# !wget -i https://coe.northeastern.edu/Research/AClab/SyRIP/annotations/400R_504S/person_keypoints_train_infant.json -P /content/Infant-Pose-Estimation/data/coco/annotations

!mkdir /content/Infant-Pose-Estimation/models/
!mkdir /content/Infant-Pose-Estimation/models/imagenet
!mkdir /content/Infant-Pose-Estimation/models/pose_coco
#remember to manually upload the models !!!!!

!nvidia-smi #check GPU runtime

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/Infant-Pose-Estimation/ 
!make

# insert into function, and RGB / PSF training
loss_object = tf.keras.losses.MeanSquareError(from_logits=False)
optimizer = tf.keras.optimizers.Adam() 

new_list = model.trainable_variables + #[R_weight,G_weight,B_weight,psf_sprd]

gradients = tape.gradient(loss, model.trainable_variables)
optimizer.apply_gradients(zip(gradients, model.trainable_variables))

"""**did you remeber to run the RGB and or BSF and string above sebi?**"""

!python /content/Infant-Pose-Estimation/pose_estimation/train_adaptive_model.py  --cfg /content/Infant-Pose-Estimation/experiments/coco/resnet50/384x288_d256x3_adam_lr1e-3_infant.yaml  --checkpoint /content/Infant-Pose-Estimation/models/pytorch/pose_coco/pose_resnet_50_384x288.pth.tar

"""grab heatmaps from below, as well as logger for acc and loss when printed vvv"""

!python /content/Infant-Pose-Estimation/pose_estimation/valid.py \ 
    --cfg /content/Infant-Pose-Estimation/experiments/coco/resnet50/384x288_d256x3_adam_lr1e-3_infant.yaml\
    --model-file /content/Infant-Pose-Estimation/models/pytorch/pose_coco/FiDIP.pth.tar

# Read image for show
img = io.imread('/content/Infant-Pose-Estimation/data/coco/images/train_infant/train00117.jpg')

# Split
red = img[:, :, 0]
green = img[:, :, 1]
blue = img[:, :, 2]

# Plot
fig, axs = plt.subplots(2,2)

cax_00 = axs[0,0].imshow(img)
axs[0,0].xaxis.set_major_formatter(plt.NullFormatter())  # kill xlabels
axs[0,0].yaxis.set_major_formatter(plt.NullFormatter())  # kill ylabels

cax_01 = axs[0,1].imshow(red, cmap='Reds_r')
fig.colorbar(cax_01, ax=axs[0,1])
axs[0,1].xaxis.set_major_formatter(plt.NullFormatter())
axs[0,1].yaxis.set_major_formatter(plt.NullFormatter())

cax_10 = axs[1,0].imshow(green, cmap='Greens_r')
fig.colorbar(cax_10, ax=axs[1,0])
axs[1,0].xaxis.set_major_formatter(plt.NullFormatter())
axs[1,0].yaxis.set_major_formatter(plt.NullFormatter())

cax_11 = axs[1,1].imshow(blue, cmap='Blues_r')
fig.colorbar(cax_11, ax=axs[1,1])
axs[1,1].xaxis.set_major_formatter(plt.NullFormatter())
axs[1,1].yaxis.set_major_formatter(plt.NullFormatter())
plt.show()

Did you remember to resart the runtime? clear previous!
  #copy here weight chnage
  stable_url = #content/Infant-Pose-Estimation/data/coco/images/validate_infant
  #ONLY FOR TRAINING
  for i in np.arange(1,501):
    num = i
    num1 = ("{:05d}".format(num))
    url=stable_url+str(num1)+".jpg"+"\n"
    img = io.imread(url)
    shape_ap = img.shape[:2]
    red = np.array(img[:, :, 0]).astype(np.float32)
    green = np.array(img[:, :, 1]).astype(np.float32)
    blue = np.array(img[:, :, 2]).astype(np.float32)

    R_weight = tf.Variable(initial_value=(np.full((shape_ap[0],shape_ap[1]), .21)),trainable=True,shape=[shape_ap[0],shape_ap[1]],dtype=tf.float32, name = 'R_weight')
    G_weight = tf.Variable(initial_value=(np.full((shape_ap[0],shape_ap[1]), .72)),trainable=True,shape=[shape_ap[0],shape_ap[1]],dtype=tf.float32, name = 'G_weight')
    B_weight = tf.Variable(initial_value=(np.full((shape_ap[0],shape_ap[1]), .07)),trainable=True,shape=[shape_ap[0],shape_ap[1]],dtype=tf.float32, name = 'B_weight')

    Grayscale = tf.math.multiply(red,R_weight)+tf.math.multiply(green,G_weight)+tf.math.multiply(blue,B_weight)

    plt.imshow(Grayscale, cmap='Greys_r')
    plt.savefig({url})

import numpy as np
import scipy.stats as st
from PIL import Image

psf_sprd = tf.Variable(initial_value=3,trainable=True,shape=(),dtype=tf.float32, name = 'psf_sprd')

def gkern(kernlen=21, nsig=3): 
    x = np.linspace(-nsig, nsig, kernlen+1)
    kern1d = np.diff(st.norm.cdf(x))
    kern2d = np.outer(kern1d, kern1d)
    return kern2d/kern2d.sum()

def reshape(image): #https://stackoverflow.com/questions/44231209/resize-rectangular-image-to-square-keeping-ratio-and-fill-background-with-black/44231784
    old_size = image.size
    max_dimension, min_dimension = max(old_size), min(old_size)
    desired_size = (max_dimension, max_dimension)
    position = int(max_dimension/2) - int(min_dimension/2) 
    blank_image = Image.new("RGB", desired_size, color='black')
    if image.height<image.width:
        blank_image.paste(image, (0, position))
    else:
        blank_image.paste(image, (position, 0))
    return blank_image,old_size[0],old_size[1]

def convolve1(image,psf):
    fft =  tf.signal.fft(image)
    shift = tf.signal.fftshift(fft)
    fftc = tf.math.multiply(shift,psf)
    sample = tf.signal.ifftshift(tf.signal.ifft2d(fftc))
    return sample

def return1(image,h, w)
  new_x = image.size[0]
  new_y = image.size[1]
  cropped_img = img.crop(((new_x-w)//2, (new_y-h)//2, (new_x+w)//2, (new_y+h)//2))
  return cropped_img

#stable_url = content/Infant-Pose-Estimation/data/coco/images/train_infant
#stable_url = content/Infant-Pose-Estimation/data/coco/images/validate_infant
for i in np.arange(,): #change, 1,501 10001,10505 0,10 10,100
    num1 = ("{:05d}".format(num)) # 1 and 2
    url=stable_url+str(num1)+".jpg"+"\n"
    img = io.imread({url})
    image, x_size, y_size = re_shape(img)
    psf = gkern(max(x_size, y_size), psf_sprd)
    image2 = convolve1(image,psf)
    final = return1(image2,x_size,y_size)
    plt.savefig({url})

# #
# def train_adaptive(config, train_III_loader, model_p, model_d, criterion_p, criterion_d, optimizer_p, optimizer_d, epoch, output_dir, tb_log_dir, writer_dict,losses_P_list, losses_D_list, acces_P_list, acces_D_list, acc_num_total, num, losses_p, acc_p, losses_d):
#     batch_time = AverageMeter()
#     data_time = AverageMeter()
#     losses_d_2 = AverageMeter()
   
#     # switch to train mode
#     model_p.train()
#     end = time.time()

#     print(len(train_III_loader))

#     num_p = 0
#     for i, (input, target, target_weight, meta) in enumerate(train_III_loader):  # 1004 mixed images to train  
#         # measure data loading time
#         data_time.update(time.time() - end)
# ...
#        if i % config.PRINT_FREQ == 0:
#             msg = 'Epoch: [{0}][{1}/{2}]\t' \
#                   'Accuracy_d {3} ({4})\t' \
#                   'Loss_d_2 {5}\t' \
#                   'Time {batch_time.val:.3f}s ({batch_time.avg:.3f}s)\t'\
#                   'Data {data_time.val:.3f}s ({data_time.avg:.3f}s)\t' \
#                   'Loss_p {loss.val:.5f} ({loss.avg:.5f})\t' \
#                   'Loss_d {loss_d.val:.5f} ({loss_d.avg:.5f})\t' \
#                   'Accuracy_p {acc.val:.3f} ({acc.avg:.3f})'.format(
#                       epoch, i, len(train_III_loader), acc_d, acc_num_total * 1.0 / num, losses_d_2.val, batch_time=batch_time,
#                       data_time=data_time, loss=losses_p, loss_d = losses_d, acc=acc_p)
#             logger.info(msg)