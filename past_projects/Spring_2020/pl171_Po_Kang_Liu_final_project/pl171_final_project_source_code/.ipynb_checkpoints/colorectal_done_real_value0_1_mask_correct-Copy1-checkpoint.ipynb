{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 641
    },
    "colab_type": "code",
    "id": "fUqilK06EbsF",
    "outputId": "eabe8ff4-701a-4166-90ed-a6f11f3a04a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow==2.0 in /usr/local/lib/python3.6/dist-packages (2.0.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (1.12.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (1.1.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (1.18.2)\n",
      "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (0.2.2)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (0.34.2)\n",
      "Requirement already satisfied: tensorboard<2.1.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (2.0.2)\n",
      "Requirement already satisfied: tensorflow-estimator<2.1.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (2.0.1)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (0.9.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (1.24.3)\n",
      "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (1.0.8)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (3.2.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (1.1.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (0.2.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (1.12.1)\n",
      "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (0.8.1)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (3.10.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (3.2.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (2.21.0)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (1.7.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (0.4.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (46.0.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (1.0.0)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==2.0) (2.8.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (2019.11.28)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (1.24.3)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (2.8)\n",
      "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (4.0)\n",
      "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (3.1.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (1.3.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (3.1.0)\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow==2.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "DtYJ1agDZ0OF",
    "outputId": "c26319bd-ca9e-4506-dc6f-27cc808d4f95"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow 2.x selected.\n"
     ]
    }
   ],
   "source": [
    "# if running in colab, this block chooses tf 2.0:\n",
    "try:\n",
    "  # %tensorflow_version only exists in Colab.\n",
    "  %tensorflow_version 2.x\n",
    "except Exception:\n",
    "  pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "icWc4wm6AG53",
    "outputId": "98f29e6c-5ac7-4198-ca39-d3b09b8fc58f",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# https://www.pyimagesearch.com/2017/NUM_CLASSES/11/image-classification-with-keras-and-deep-learning/\n",
    "# https://machinelearningmastery.com/grid-search-hyperparameters-deep-learning-models-python-keras/\n",
    "# https://machinelearningmastery.com/save-load-keras-deep-learning-models/\n",
    "#https://www.learnopencv.com/image-classification-using-convolutional-neural-networks-in-keras/\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import cv2\n",
    "import matplotlib\n",
    "from subprocess import check_output\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import math as m\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "XkPEyvJkJxmp",
    "outputId": "34a198b1-5d4d-433b-cac7-8d56cd59c307"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0'"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "XSHGTLzz0k2L",
    "outputId": "46713479-1e7d-4b90-d519-426c6a4a228e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pynput in /usr/local/lib/python3.6/dist-packages (1.6.8)\n",
      "Requirement already satisfied: python-xlib>=0.17; \"linux\" in sys_platform in /usr/local/lib/python3.6/dist-packages (from pynput) (0.26)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from pynput) (1.12.0)\n"
     ]
    }
   ],
   "source": [
    "pip install pynput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "XusiVcbbH0_3",
    "outputId": "d5e8717b-78a4-4982-a6bd-616b984902a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KlVJFMocug9x"
   },
   "source": [
    "## uncomment it if we want to redownload the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "_jKY0S-QAVkT",
    "outputId": "d0343145-43f1-4df8-9f02-679a08bdef5a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport tensorflow_datasets as tfds\\n#dataset = tfds.image.mnist\\n# https://www.tensorflow.org/datasets/api_docs/python/tfds/core/DatasetBuilder\\n\\nmalaria_builder = tfds.builder(\"colorectal_histology\")\\nmalaria_info = malaria_builder.info\\nmalaria_builder.download_and_prepare()\\ndatasets = malaria_builder.as_dataset()\\ndatasets\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import tensorflow_datasets as tfds\n",
    "#dataset = tfds.image.mnist\n",
    "# https://www.tensorflow.org/datasets/api_docs/python/tfds/core/DatasetBuilder\n",
    "\n",
    "malaria_builder = tfds.builder(\"colorectal_histology\")\n",
    "malaria_info = malaria_builder.info\n",
    "malaria_builder.download_and_prepare()\n",
    "datasets = malaria_builder.as_dataset()\n",
    "datasets\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "pQaDY-H_Iv5C",
    "outputId": "6a6bca01-f3bc-41e8-dc2b-254536b79bbb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntrain_dataset = datasets[\"train\"]\\nimage_array = np.array([])\\nlabel_array = np.array([])\\nfor example in tfds.as_numpy(train_dataset):\\n  image, label = example[\\'image\\'], example[\\'label\\']\\n  label = np.expand_dims(label, axis=0)\\n  image = np.expand_dims(image, axis=0)\\n  \\n  #print(label.shape)\\n  #sample[\"image\"] = cv2.resize(image, dim, interpolation = cv2.INTER_AREA)\\n  image_array=np.vstack((image_array,image)) if image_array.size else image\\n  label_array = np.append(label_array,label, axis=0)\\n  #print(sample[\"image\"].shape)\\n  '"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "train_dataset = datasets[\"train\"]\n",
    "image_array = np.array([])\n",
    "label_array = np.array([])\n",
    "for example in tfds.as_numpy(train_dataset):\n",
    "  image, label = example['image'], example['label']\n",
    "  label = np.expand_dims(label, axis=0)\n",
    "  image = np.expand_dims(image, axis=0)\n",
    "  \n",
    "  #print(label.shape)\n",
    "  #sample[\"image\"] = cv2.resize(image, dim, interpolation = cv2.INTER_AREA)\n",
    "  image_array=np.vstack((image_array,image)) if image_array.size else image\n",
    "  label_array = np.append(label_array,label, axis=0)\n",
    "  #print(sample[\"image\"].shape)\n",
    "  '''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a82MjOnsurUR"
   },
   "source": [
    "## seems like no use, haha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "PmQ4sp1SDoZj",
    "outputId": "b8bf6754-963c-454a-9a63-b1991b0c3a30"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport cv2\\nimport numpy as np\\nwidth = 128\\nheight =128\\nchannel = 3\\ndim = (width, height)\\n# resize image\\ntrain_dataset = datasets[\"train\"]\\n\\n#mnist_example = train_dataset.take(50)\\nmnist_example = train_dataset.take(50)\\nimage_array = np.array([])\\nlabel_array = np.array([])\\nfor sample in mnist_example:\\n    image, label = sample[\"image\"].numpy(), sample[\"label\"].numpy()\\n    image = np.expand_dims(image, axis=0)\\n    #print(image.shape)\\n\\n    \\n    #print(image_array.shape)\\n   \\n    label = np.expand_dims(label, axis=0)\\n    #print(label.shape)\\n    #sample[\"image\"] = cv2.resize(image, dim, interpolation = cv2.INTER_AREA)\\n    image_array=np.vstack((image_array,image)) if image_array.size else image\\n    label_array = np.append(label_array,label, axis=0)\\n    #print(sample[\"image\"].shape)\\n    #plt.imshow(sample[\"image\"][:, :, 0], cmap=plt.get_cmap(\"gray\"))\\n    #plt.show()\\n    #print(\"Label: %d\" % label)\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import cv2\n",
    "import numpy as np\n",
    "width = 128\n",
    "height =128\n",
    "channel = 3\n",
    "dim = (width, height)\n",
    "# resize image\n",
    "train_dataset = datasets[\"train\"]\n",
    "\n",
    "#mnist_example = train_dataset.take(50)\n",
    "mnist_example = train_dataset.take(50)\n",
    "image_array = np.array([])\n",
    "label_array = np.array([])\n",
    "for sample in mnist_example:\n",
    "    image, label = sample[\"image\"].numpy(), sample[\"label\"].numpy()\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    #print(image.shape)\n",
    "\n",
    "    \n",
    "    #print(image_array.shape)\n",
    "   \n",
    "    label = np.expand_dims(label, axis=0)\n",
    "    #print(label.shape)\n",
    "    #sample[\"image\"] = cv2.resize(image, dim, interpolation = cv2.INTER_AREA)\n",
    "    image_array=np.vstack((image_array,image)) if image_array.size else image\n",
    "    label_array = np.append(label_array,label, axis=0)\n",
    "    #print(sample[\"image\"].shape)\n",
    "    #plt.imshow(sample[\"image\"][:, :, 0], cmap=plt.get_cmap(\"gray\"))\n",
    "    #plt.show()\n",
    "    #print(\"Label: %d\" % label)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6BdSn6NMIFL0"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dhLPaS8_u0o9"
   },
   "source": [
    "#uncomment it if we want to redownload and save the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "qiEX48qn9p7k",
    "outputId": "8a4d1f7d-c3e8-4291-ffd5-043ca833a521"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfrom numpy import save\\n# define data\\n# save to npy file\\nsave('/content/drive/My Drive/Colab Notebooks/machine learning in imaging/final project/image_array_colorectal2.npy', image_array)\\nfiles.download('/content/drive/My Drive/Colab Notebooks/machine learning in imaging/final project/image_array_colorectal2.npy')\\nsave('/content/drive/My Drive/Colab Notebooks/machine learning in imaging/final project/label_array_colorectal2.npy', label_array)\\nfiles.download('/content/drive/My Drive/Colab Notebooks/machine learning in imaging/final project/label_array_colorectal2.npy')\\n\""
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from numpy import save\n",
    "# define data\n",
    "# save to npy file\n",
    "save('/content/drive/My Drive/Colab Notebooks/machine learning in imaging/final project/image_array_colorectal2.npy', image_array)\n",
    "files.download('/content/drive/My Drive/Colab Notebooks/machine learning in imaging/final project/image_array_colorectal2.npy')\n",
    "save('/content/drive/My Drive/Colab Notebooks/machine learning in imaging/final project/label_array_colorectal2.npy', label_array)\n",
    "files.download('/content/drive/My Drive/Colab Notebooks/machine learning in imaging/final project/label_array_colorectal2.npy')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oPJ1TkRDl8Oz"
   },
   "outputs": [],
   "source": [
    "from numpy import load\n",
    "\n",
    "image_array = load('/content/drive/My Drive/Colab Notebooks/machine learning in imaging/final project/image_array_colorectal2.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "p-UUhP9t4yey",
    "outputId": "d81f9bc9-93c7-4453-a1cb-a4ada94de964"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 150, 150, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numpy import load\n",
    "#image_array = load('/content/drive/My Drive/Colab Notebooks/machine learning in imaging/final project/image_array_colorectal.npy')\n",
    "label_array = load('/content/drive/My Drive/Colab Notebooks/machine learning in imaging/final project/label_array_colorectal2.npy')\n",
    "image_array = image_array/255\n",
    "# print the array\n",
    "image_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 888
    },
    "colab_type": "code",
    "id": "qtefGG36vmMT",
    "outputId": "3836174e-8179-4978-ba8c-467f45ea4c30"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.41568627, 0.18431373, 0.34117647],\n",
       "        [0.50196078, 0.27058824, 0.42745098],\n",
       "        [0.52941176, 0.28235294, 0.44705882],\n",
       "        ...,\n",
       "        [0.63137255, 0.34901961, 0.54509804],\n",
       "        [0.52941176, 0.31764706, 0.51372549],\n",
       "        [0.4745098 , 0.2627451 , 0.45882353]],\n",
       "\n",
       "       [[0.35686275, 0.1372549 , 0.3254902 ],\n",
       "        [0.45098039, 0.23137255, 0.41960784],\n",
       "        [0.49411765, 0.24705882, 0.44705882],\n",
       "        ...,\n",
       "        [0.6       , 0.36470588, 0.55294118],\n",
       "        [0.56078431, 0.3372549 , 0.5372549 ],\n",
       "        [0.51764706, 0.29411765, 0.49411765]],\n",
       "\n",
       "       [[0.27058824, 0.11764706, 0.27843137],\n",
       "        [0.34117647, 0.18823529, 0.34901961],\n",
       "        [0.46666667, 0.20392157, 0.40392157],\n",
       "        ...,\n",
       "        [0.57254902, 0.34509804, 0.54509804],\n",
       "        [0.59607843, 0.37254902, 0.58039216],\n",
       "        [0.55686275, 0.33333333, 0.54117647]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.90196078, 0.90980392, 0.89803922],\n",
       "        [0.92156863, 0.92941176, 0.91764706],\n",
       "        [0.92941176, 0.90588235, 0.94509804],\n",
       "        ...,\n",
       "        [0.81176471, 0.71764706, 0.81176471],\n",
       "        [0.77647059, 0.67058824, 0.8       ],\n",
       "        [0.69019608, 0.58431373, 0.71372549]],\n",
       "\n",
       "       [[0.90588235, 0.90588235, 0.90588235],\n",
       "        [0.92941176, 0.92941176, 0.92941176],\n",
       "        [0.93333333, 0.91372549, 0.9372549 ],\n",
       "        ...,\n",
       "        [0.83137255, 0.72941176, 0.83529412],\n",
       "        [0.78823529, 0.68235294, 0.80392157],\n",
       "        [0.69803922, 0.59215686, 0.71372549]],\n",
       "\n",
       "       [[0.91764706, 0.90980392, 0.92941176],\n",
       "        [0.92941176, 0.92156863, 0.94117647],\n",
       "        [0.93333333, 0.91372549, 0.92941176],\n",
       "        ...,\n",
       "        [0.8627451 , 0.75294118, 0.85098039],\n",
       "        [0.80784314, 0.69411765, 0.81176471],\n",
       "        [0.72156863, 0.60784314, 0.7254902 ]]])"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_array[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "L1Gb6hbZjNXw",
    "outputId": "3ed86563-b309-475c-ed5b-c7f8e4bf6195"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000,)\n",
      "(5000, 150, 150, 3)\n"
     ]
    }
   ],
   "source": [
    "print(label_array.shape)\n",
    "print(image_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bkdXXcLrc9fq"
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split( image_array, label_array, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AB6plDhEc9dO"
   },
   "outputs": [],
   "source": [
    "#x_train = tf.cast(x_train,tf.float32)\n",
    "#x_train = x_train[..., tf.newaxis]\n",
    "\n",
    "#x_test = tf.cast(x_test,tf.float32)\n",
    "\n",
    "#x_test = x_test[..., tf.newaxis]\n",
    "#y_train = tf.cast(y_train,tf.int32)\n",
    "#y_test = tf.cast(y_test,tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "esm-B43OezGg"
   },
   "outputs": [],
   "source": [
    "#x_train = tf.Variable(x_train,dtype=tf.complex64)\n",
    "#x_test = tf.Variable(x_test,dtype=tf.complex64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "QD6lfzXOg_Zm",
    "outputId": "acef544c-d956-4467-c4a6-157aaca4bc08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3750, 150, 150, 3) (3750,)\n",
      "(1250, 150, 150, 3) (1250,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, y_train.shape)\n",
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ca6-dUyyc9GZ"
   },
   "outputs": [],
   "source": [
    "train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(10000).batch(32)\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "77p47l_DGPpS",
    "outputId": "20cc6712-6c45-41e5-d4fe-4f931755bbf6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_array[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "O7ZArxjiDoSL",
    "outputId": "3c3f5c71-8386-405f-a2ce-dc915b8c0997"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor i in range(10):\\n  print(label_array[i])\\n  plt.imshow(image_array[i])\\n  plt.show()\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "for i in range(10):\n",
    "  print(label_array[i])\n",
    "  plt.imshow(image_array[i])\n",
    "  plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 888
    },
    "colab_type": "code",
    "id": "ScC-b8ZinGg9",
    "outputId": "70c2cf90-0def-461d-9109-e43725124995"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.41568627, 0.18431373, 0.34117647],\n",
       "        [0.50196078, 0.27058824, 0.42745098],\n",
       "        [0.52941176, 0.28235294, 0.44705882],\n",
       "        ...,\n",
       "        [0.63137255, 0.34901961, 0.54509804],\n",
       "        [0.52941176, 0.31764706, 0.51372549],\n",
       "        [0.4745098 , 0.2627451 , 0.45882353]],\n",
       "\n",
       "       [[0.35686275, 0.1372549 , 0.3254902 ],\n",
       "        [0.45098039, 0.23137255, 0.41960784],\n",
       "        [0.49411765, 0.24705882, 0.44705882],\n",
       "        ...,\n",
       "        [0.6       , 0.36470588, 0.55294118],\n",
       "        [0.56078431, 0.3372549 , 0.5372549 ],\n",
       "        [0.51764706, 0.29411765, 0.49411765]],\n",
       "\n",
       "       [[0.27058824, 0.11764706, 0.27843137],\n",
       "        [0.34117647, 0.18823529, 0.34901961],\n",
       "        [0.46666667, 0.20392157, 0.40392157],\n",
       "        ...,\n",
       "        [0.57254902, 0.34509804, 0.54509804],\n",
       "        [0.59607843, 0.37254902, 0.58039216],\n",
       "        [0.55686275, 0.33333333, 0.54117647]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.90196078, 0.90980392, 0.89803922],\n",
       "        [0.92156863, 0.92941176, 0.91764706],\n",
       "        [0.92941176, 0.90588235, 0.94509804],\n",
       "        ...,\n",
       "        [0.81176471, 0.71764706, 0.81176471],\n",
       "        [0.77647059, 0.67058824, 0.8       ],\n",
       "        [0.69019608, 0.58431373, 0.71372549]],\n",
       "\n",
       "       [[0.90588235, 0.90588235, 0.90588235],\n",
       "        [0.92941176, 0.92941176, 0.92941176],\n",
       "        [0.93333333, 0.91372549, 0.9372549 ],\n",
       "        ...,\n",
       "        [0.83137255, 0.72941176, 0.83529412],\n",
       "        [0.78823529, 0.68235294, 0.80392157],\n",
       "        [0.69803922, 0.59215686, 0.71372549]],\n",
       "\n",
       "       [[0.91764706, 0.90980392, 0.92941176],\n",
       "        [0.92941176, 0.92156863, 0.94117647],\n",
       "        [0.93333333, 0.91372549, 0.92941176],\n",
       "        ...,\n",
       "        [0.8627451 , 0.75294118, 0.85098039],\n",
       "        [0.80784314, 0.69411765, 0.81176471],\n",
       "        [0.72156863, 0.60784314, 0.7254902 ]]])"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_array[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UExxTurMpLp7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0cdqpF-frSWh"
   },
   "source": [
    "# sample phase\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hBf-a9zlrU8Y"
   },
   "outputs": [],
   "source": [
    "#sample_phase = sample\n",
    "#optical_thickness = 20 * wavelength\n",
    "#sample = sample * np.exp(1j * sample_phase*optical_thickness/wavelength) #complex exponential represents phase delay\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "awV2fwrTwlSM"
   },
   "source": [
    "# some parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mkCoyotPwled"
   },
   "outputs": [],
   "source": [
    "wavelength_ = .5e-3          # units are mm\n",
    "optical_thickness_ = 20 * wavelength_\n",
    "\n",
    "wavelength = tf.constant(wavelength_, dtype=tf.complex64)\n",
    "optical_thickness = tf.constant(optical_thickness_, dtype=tf.complex64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "18RdBj3_phxL"
   },
   "source": [
    "# input_illumination_phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HVlGGApspLxu"
   },
   "outputs": [],
   "source": [
    "#input_illumination_phase = tf.Variable(tf.ones([28,28]),dtype=tf.float32,trainable=True,name='input_illumination_phase')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jIwPJjHBpL8p"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gz5UGLG7rwvF"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2HVlpZIWrxFO"
   },
   "source": [
    "# RGB color filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZLnA3hs-r1bs"
   },
   "outputs": [],
   "source": [
    "color_filter_tmp = np.ones([3,150,150])\n",
    "color_filter_ = tf.Variable(color_filter_tmp,dtype=tf.float32,trainable=True,name='color_filter_')\n",
    "#color_filter_ = tf.expand_dims(color_filter_, 0) # add extra axis for batch size\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lCPfy1lXo8sl"
   },
   "source": [
    "## phase mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UNWyXCiYxg69"
   },
   "outputs": [],
   "source": [
    "aaa = np.ones((150,150))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "kvIjnanNpAKr",
    "outputId": "9fc7410a-43d9-4112-f37c-1318849d9e32"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\noptical_phase_mask = tf.Variable(aaa,dtype=tf.float32,trainable=True,name='optical_phase_mask')\\noptical_phase_mask.dtype\\noptical_phase_mask = tf.expand_dims(optical_phase_mask, 0) # add extra axis for batch size\\n\""
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "optical_phase_mask = tf.Variable(aaa,dtype=tf.float32,trainable=True,name='optical_phase_mask')\n",
    "optical_phase_mask.dtype\n",
    "optical_phase_mask = tf.expand_dims(optical_phase_mask, 0) # add extra axis for batch size\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o-5vdvDkpcXh"
   },
   "source": [
    "### constraint of optical_phase_mask ??????\n",
    "\n",
    "\n",
    "1.   No constraint\n",
    "2.   Real value\n",
    "3. complex value with mahnitute = 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X1W-XXeXpfo9"
   },
   "outputs": [],
   "source": [
    "# a = tf.get_variable('a', shape=[], constraint=lambda t: tf.clip_by_value(t, -2, 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ITbGWUoIpf4d"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gWcFKxV9o84V"
   },
   "source": [
    "## Aperture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uxM5VqZbpzLN"
   },
   "outputs": [],
   "source": [
    "# define total range of spatial frequency axis, 1/mm\n",
    "#fxmax = 1/delta_x\n",
    "# make linspace, meshgrid as needed\n",
    "num_samples = 150\n",
    "fxmax= 75\n",
    "fx = np.linspace(-fxmax, fxmax,num_samples)\n",
    "fy = fx\n",
    "[fxx,fyy] = np.meshgrid(fx, fy)\n",
    "# Take 2D fourier transform of sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "colab_type": "code",
    "id": "WbMc4pAqqMwz",
    "outputId": "63ddf869-20e7-4a06-d48e-3a3c61987893"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQ8AAAEKCAYAAAAM4tCNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define lens numerical aperture as percentage of total width of spatial freqeuncy domain\n",
    "na = .25 * fxmax\n",
    "# Define lens transfer function as matrix with 1's within desired radius, 0's outside\n",
    "lens_transfer_functiontmp = (np.sqrt(fxx**2+fyy**2))<na\n",
    "#lens_transfer_function = tf.cast(lens_transfer_function,tf.complex64)\n",
    "\n",
    "# Plot what the transfer function looks like\n",
    "plt.imshow(lens_transfer_functiontmp)\n",
    "plt.xlabel('spatial frequency (1/mm)')\n",
    "plt.ylabel('spatial frequency (1/mm)')\n",
    "plt.show()\n",
    "\n",
    "lens_transfer_function = tf.Variable(lens_transfer_functiontmp,dtype=tf.float32,trainable=False,name='lens_transfer_function')\n",
    "\n",
    "#lens_transfer_function = tf.cast(lens_transfer_function,tf.complex64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "apBHeYHS-0RC"
   },
   "outputs": [],
   "source": [
    "#aperture_phase = tf.Variable(tf.ones([150,150]),dtype=tf.float32,trainable=True,name='aperture_phase')\n",
    "#aperture_phase = tf.expand_dims(aperture_phase, 0) # add extra axis for batch size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hty0cO7ZV-09"
   },
   "outputs": [],
   "source": [
    "tmp = np.ones((150,150))\n",
    "tmp = tmp/2 # initial value would be 0.5 for all guys\n",
    "real_aperture_mask = tf.Variable(tmp,dtype=tf.float32,trainable=True,name='real_aperture_mask')\n",
    "#real_aperture_mask = tf.clip_by_value(real_aperture_mask,clip_value_max=)\n",
    "#real_aperture_mask = tf.Variable(initial_value = tf.initializers.GlorotNormal()(shape=(150,150)),dtype=tf.float32,trainable=True,name='real_aperture_mask')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "xa_n8apWV4ob",
    "outputId": "308ceca3-4ef0-4065-d150-fee5ef3f351e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport tfplot\\n@tfplot.autowrap(figsize=(3, 3))\\ndef plot_imshow(img):\\n   fig, ax = tfplot.subplots()\\n   ax.imshow(img)\\n   return fig\\n'"
      ]
     },
     "execution_count": 31,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import tfplot\n",
    "@tfplot.autowrap(figsize=(3, 3))\n",
    "def plot_imshow(img):\n",
    "   fig, ax = tfplot.subplots()\n",
    "   ax.imshow(img)\n",
    "   return fig\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nBYQsK6QWhXs"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XLvsWqJg-0fQ"
   },
   "source": [
    "## test physical layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Uzg5xxSeOOut"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "EBa54Pi3-0sH",
    "outputId": "9ca507fc-87b6-4bdb-db85-55295a902e4f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 150, 150, 3)"
      ]
     },
     "execution_count": 32,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_batch_test = x_train [:32]\n",
    "x_batch_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Evz9G9Zmap1z"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fx5tgU-vaqHm"
   },
   "outputs": [],
   "source": [
    "#tf_plot = tfplot.wrap(plt.imshow, name=\"MyPlot\", batch=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "XJCuL5b3_G7A",
    "outputId": "dff096ea-6610-4ece-e886-ad8a0e8f5154"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[  0.   1.   2.   3.   4.]\n",
      "   [  5.   6.   7.   8.   9.]\n",
      "   [ 10.  11.  12.  13.  14.]\n",
      "   [ 15.  16.  17.  18.  19.]]\n",
      "\n",
      "  [[ 20.  21.  22.  23.  24.]\n",
      "   [ 25.  26.  27.  28.  29.]\n",
      "   [ 30.  31.  32.  33.  34.]\n",
      "   [ 35.  36.  37.  38.  39.]]\n",
      "\n",
      "  [[ 40.  41.  42.  43.  44.]\n",
      "   [ 45.  46.  47.  48.  49.]\n",
      "   [ 50.  51.  52.  53.  54.]\n",
      "   [ 55.  56.  57.  58.  59.]]]\n",
      "\n",
      "\n",
      " [[[ 60.  61.  62.  63.  64.]\n",
      "   [ 65.  66.  67.  68.  69.]\n",
      "   [ 70.  71.  72.  73.  74.]\n",
      "   [ 75.  76.  77.  78.  79.]]\n",
      "\n",
      "  [[ 80.  81.  82.  83.  84.]\n",
      "   [ 85.  86.  87.  88.  89.]\n",
      "   [ 90.  91.  92.  93.  94.]\n",
      "   [ 95.  96.  97.  98.  99.]]\n",
      "\n",
      "  [[100. 101. 102. 103. 104.]\n",
      "   [105. 106. 107. 108. 109.]\n",
      "   [110. 111. 112. 113. 114.]\n",
      "   [115. 116. 117. 118. 119.]]]]\n",
      "[[ 0.  1.  2.  3.  4.]\n",
      " [ 5.  6.  7.  8.  9.]\n",
      " [10. 11. 12. 13. 14.]\n",
      " [15. 16. 17. 18. 19.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=44, shape=(2, 3, 4, 5), dtype=float64, numpy=\n",
       "array([[[[0.000e+00, 1.000e+00, 4.000e+00, 9.000e+00, 1.600e+01],\n",
       "         [2.500e+01, 3.600e+01, 4.900e+01, 6.400e+01, 8.100e+01],\n",
       "         [1.000e+02, 1.210e+02, 1.440e+02, 1.690e+02, 1.960e+02],\n",
       "         [2.250e+02, 2.560e+02, 2.890e+02, 3.240e+02, 3.610e+02]],\n",
       "\n",
       "        [[0.000e+00, 2.100e+01, 4.400e+01, 6.900e+01, 9.600e+01],\n",
       "         [1.250e+02, 1.560e+02, 1.890e+02, 2.240e+02, 2.610e+02],\n",
       "         [3.000e+02, 3.410e+02, 3.840e+02, 4.290e+02, 4.760e+02],\n",
       "         [5.250e+02, 5.760e+02, 6.290e+02, 6.840e+02, 7.410e+02]],\n",
       "\n",
       "        [[0.000e+00, 4.100e+01, 8.400e+01, 1.290e+02, 1.760e+02],\n",
       "         [2.250e+02, 2.760e+02, 3.290e+02, 3.840e+02, 4.410e+02],\n",
       "         [5.000e+02, 5.610e+02, 6.240e+02, 6.890e+02, 7.560e+02],\n",
       "         [8.250e+02, 8.960e+02, 9.690e+02, 1.044e+03, 1.121e+03]]],\n",
       "\n",
       "\n",
       "       [[[0.000e+00, 6.100e+01, 1.240e+02, 1.890e+02, 2.560e+02],\n",
       "         [3.250e+02, 3.960e+02, 4.690e+02, 5.440e+02, 6.210e+02],\n",
       "         [7.000e+02, 7.810e+02, 8.640e+02, 9.490e+02, 1.036e+03],\n",
       "         [1.125e+03, 1.216e+03, 1.309e+03, 1.404e+03, 1.501e+03]],\n",
       "\n",
       "        [[0.000e+00, 8.100e+01, 1.640e+02, 2.490e+02, 3.360e+02],\n",
       "         [4.250e+02, 5.160e+02, 6.090e+02, 7.040e+02, 8.010e+02],\n",
       "         [9.000e+02, 1.001e+03, 1.104e+03, 1.209e+03, 1.316e+03],\n",
       "         [1.425e+03, 1.536e+03, 1.649e+03, 1.764e+03, 1.881e+03]],\n",
       "\n",
       "        [[0.000e+00, 1.010e+02, 2.040e+02, 3.090e+02, 4.160e+02],\n",
       "         [5.250e+02, 6.360e+02, 7.490e+02, 8.640e+02, 9.810e+02],\n",
       "         [1.100e+03, 1.221e+03, 1.344e+03, 1.469e+03, 1.596e+03],\n",
       "         [1.725e+03, 1.856e+03, 1.989e+03, 2.124e+03, 2.261e+03]]]])>"
      ]
     },
     "execution_count": 34,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aaa = np.zeros(2*3*4*5)\n",
    "for i in range(2*3*4*5):\n",
    "  aaa[i] = i\n",
    "aaa = aaa.reshape((2,3,4,5))\n",
    "aaa.shape\n",
    "\n",
    "bbb = np.zeros(4 * 5)\n",
    "for i in range(4*5):\n",
    "  bbb[i] = i\n",
    "bbb = bbb.reshape((4,5))\n",
    "print(aaa)\n",
    "\n",
    "print(bbb)\n",
    "tf.multiply(aaa,bbb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4S6ERk1ipsZn"
   },
   "source": [
    "# physical layer RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6n_oT63WxQ22"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "def physical_layer_RGB(x_batch):\n",
    "  print('123123123')\n",
    "  print('x_batch shape', x_batch.shape)\n",
    "\n",
    "    #### sample phase #####\n",
    "    \n",
    "\n",
    "  sample = tf.cast(x_batch, tf.complex64)\n",
    "  #sample_phase = sample\n",
    "  print('1111')\n",
    "  #sample = sample * tf.exp(1j * sample_phase*optical_thickness/wavelength) #complex exponential represents phase delay\n",
    "\n",
    "  print('2222')\n",
    "\n",
    "  #### OPTICS #####\n",
    "\n",
    "  sample = tf.transpose(sample, perm=[0,3,1,2])\n",
    "\n",
    "  print('channel G sample 1')\n",
    "  \n",
    "  #tfplot.plot(plt.imshow,sample[1,1,:,:])\n",
    "  ##ax.imshow(sample[1,1,:,:])  \n",
    "  #tfplot.show()\n",
    "  \n",
    "  \n",
    "  #plot_imshow(tf.cast((sample[1,1,:,:]),tf.float32))\n",
    "  print('channel G sample 1 original')\n",
    "\n",
    "  #plt.imshow(tf.cast((sample[1,1,:,:]),tf.float32))\n",
    "  #plt.show()\n",
    "\n",
    "  #FT_sample = tf.Variable(sample,dtype=tf.complex64,trainable=False)\n",
    "  FT_sample = tf.signal.fft2d(sample)\n",
    "  FT_sample_shift = tf.signal.fftshift(FT_sample,axes=(2,3))\n",
    "\n",
    "  print('after color filter')\n",
    "  color_filter_2 = tf.cast(color_filter_, tf.complex64)\n",
    "\n",
    "  filtered_FT_sample  =tf.multiply(color_filter_2,FT_sample_shift) \n",
    "  #plt.imshow(tf.cast(filtered_FT_sample[1,1,:,:],tf.float32))\n",
    "  #plt.show()\n",
    "  \n",
    "  aperture_phase2 = tf.cast(aperture_phase, tf.complex64)\n",
    "  aperture = lens_transfer_function * tf.exp(1j * 2* m.pi* aperture_phase2)\n",
    "  filtered_FT_sample  =tf.multiply(aperture,filtered_FT_sample) \n",
    "\n",
    "  print('after transfer function ')\n",
    "  filtered_FT_sample  =tf.multiply(lens_transfer_function,filtered_FT_sample) \n",
    "  #plt.imshow(tf.cast(filtered_FT_sample[1,1,:,:],tf.float32))\n",
    "  #plt.show()\n",
    "\n",
    "\n",
    "  print('after ifft2d ')\n",
    "  image = tf.signal.ifft2d(filtered_FT_sample)\n",
    "  #plt.imshow(abs(image[1,1,:,:]))\n",
    "  #plt.show()\n",
    "\n",
    "\n",
    "  print('after repermutation :tf.transpose(image, perm=[0,2,3,1]) ')\n",
    "  image = tf.transpose(image, perm=[0,2,3,1])\n",
    "  #plt.imshow(abs(image[1,:,:,1]))\n",
    "  #plt.show()\n",
    "\n",
    "  image = tf.square(tf.abs(image)) #convert it to intensity\n",
    "  #image = tf.square(((image) * tf.math.conj(image))) #convert it to intensity\n",
    "  image = tf.cast(image, tf.float32)\n",
    "  print('image shape after physical layer',image.shape)\n",
    "\n",
    "  ######### add some gaussian noise with stdev of 0.2, to simulate detector noise:\n",
    "  #noise_sig = 1\n",
    "  #noise = noise_sig  *  tf.random.normal([28,28],mean=0,stddev=0.2)\n",
    "  #print(noise)\n",
    "  #image += noise\n",
    "  \n",
    "  #########  image += noise\n",
    "\n",
    "  # if you didn't already, add color channel singleton dimension in preparation\n",
    "  # for processing through a CNN:\n",
    "  #image = image[..., tf.newaxis]\n",
    "\n",
    "  #return image-1\n",
    "  return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sU4RO4rn91v-"
   },
   "source": [
    "# physical layer phase mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kL4mk9ATmy5v"
   },
   "outputs": [],
   "source": [
    "def physical_layer_phase_mask(x_batch):\n",
    "  print('aaa')\n",
    "\n",
    "\n",
    "  #### sample phase #####\n",
    "  x_batch = tf.cast(x_batch, tf.complex64)\n",
    "  print('ccc')\n",
    "  sample = x_batch\n",
    "  ##sample_phase = sample\n",
    "  #sample = sample * np.exp(1j * sample_phase*optical_thickness/wavelength) #complex exponential represents phase delay\n",
    "\n",
    "\n",
    "#### OPTICS #####\n",
    "  sample = tf.transpose(sample, perm=[0,3,1,2])\n",
    "  print('ddd')\n",
    "\n",
    "  FT_sample  = tf.signal.fft2d(sample )\n",
    "  FT_sample_shift = tf.signal.fftshift(FT_sample,axes=(2,3))\n",
    "  print('eee')\n",
    "\n",
    "  #real_aperture_mask2 = tf.clip_by_value(real_aperture_mask, clip_value_min=0, clip_value_max=1) # [[1, 3, 3],[3, 3, 3]]\n",
    "  real_aperture_mask2 = tf.square(real_aperture_mask)\n",
    "  #aperture_phase2 = tf.cast(aperture_phase, tf.complex64)\n",
    "\n",
    "  #lens_transfer_function = tf.cast(lens_transfer_function,tf.float32)\n",
    "  aperture = tf.multiply(lens_transfer_function, real_aperture_mask2)\n",
    "  aperture2 = tf.cast(aperture,tf.complex64)\n",
    "  print('fff')\n",
    "\n",
    "  filtered_FT_sample  =tf.multiply(aperture2, FT_sample_shift) \n",
    "\n",
    "\n",
    "######## imshow test >?????\n",
    " ## plt.imshow(np.abs(filtered_FT_sample[1,1,:,:]))#.astype(np.float32))\n",
    " # plt.show()\n",
    "\n",
    "\n",
    "\n",
    "#### IFFT  and form the image!!! #################\n",
    "  image = tf.signal.ifft2d(filtered_FT_sample)\n",
    "  image = tf.transpose(image, perm=[0,2,3,1])\n",
    "\n",
    "  image = tf.square(tf.abs(image)) #convert it to intensity\n",
    "\n",
    "  #image = tf.square(((image) * tf.math.conj(image))) #convert it to intensity\n",
    "  image = tf.cast(image, tf.float32)\n",
    "  \n",
    "  ######### add some gaussian noise with stdev of 0.2, to simulate detector noise:\n",
    "  #noise_sig = 1\n",
    "  #noise = noise_sig  *  tf.random.normal([28,28],mean=0,stddev=0.2)\n",
    "  #print(noise)\n",
    "  #image += noise\n",
    "  \n",
    "  #########  image += noise\n",
    "\n",
    "  # if you didn't already, add color channel singleton dimension in preparation\n",
    "  # for processing through a CNN:\n",
    "  #image = image[..., tf.newaxis]\n",
    "\n",
    "  #return image-1\n",
    "  return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qpe_ccskpn2N"
   },
   "source": [
    "# alexnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8SF9jEaIzmI8"
   },
   "outputs": [],
   "source": [
    "# https://www.google.com/search?q=alexnet&sxsrf=ALeKk03nxwjPnSPq77l41iACT4nuWtF0nw:1584470777490&source=lnms&tbm=isch&sa=X&ved=2ahUKEwiGl-XOlaLoAhXtT98KHVwTCIIQ_AUoAXoECA0QAw&biw=1280&bih=529#imgrc=j8y8gy88lYqI-M\n",
    "#https://github.com/henrypowell87/AlexNet_TF2.0/blob/master/main.py\n",
    "\n",
    "\n",
    "class Alexnet(tf.keras.Model):\n",
    "  def __init__(self):\n",
    "    super(Alexnet, self).__init__()\n",
    "    self.conv_1 =    tf.keras.layers.Conv2D(filters=96, kernel_size=11, strides=4, padding='same', activation='relu')\n",
    "    self.pool_1 =    tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2),padding=\"valid\")\n",
    "    self.norm_1 =    tf.keras.layers.BatchNormalization()\n",
    "    \n",
    "    self.conv_2 =    tf.keras.layers.Conv2D(filters=256, kernel_size=5, strides=1, padding='same', activation='relu')\n",
    "    self.pool_2 =    tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2),padding=\"valid\")\n",
    "    self.norm_2 =    tf.keras.layers.BatchNormalization()\n",
    "\n",
    "    self.conv_3 =    tf.keras.layers.Conv2D(filters=384, kernel_size=3, strides=1, padding='valid', activation='relu')\n",
    "    self.norm_3 =    tf.keras.layers.BatchNormalization()\n",
    "\n",
    "    self.conv_4 =    tf.keras.layers.Conv2D(filters=384, kernel_size=3, strides=1, padding='valid', activation='relu')\n",
    "    self.norm_4 =    tf.keras.layers.BatchNormalization()\n",
    "\n",
    "\n",
    "    self.conv_5 =    tf.keras.layers.Conv2D(filters=256, kernel_size=3, strides=1, padding='same', activation='relu')\n",
    "    self.pool_5 =    tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2),padding=\"valid\")\n",
    "    self.norm_5 =    tf.keras.layers.BatchNormalization()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #self.block_5 =    tf.keras.layers.Conv2D(filters=64, kernel_size=3, strides=2, padding='same', activation='relu')\n",
    "    self.flat = tf.keras.layers.Flatten()\n",
    "\n",
    "    self.dense_6 = tf.keras.layers.Dense(units=4096, activation='relu')\n",
    "    self.drop_6 = tf.keras.layers.Dropout(rate=0.4)\n",
    "    self.norm_6 =    tf.keras.layers.BatchNormalization()\n",
    "\n",
    "    self.dense_7 = tf.keras.layers.Dense(units=4096, activation='relu')\n",
    "    self.drop_7 = tf.keras.layers.Dropout(rate=0.4)\n",
    "    self.norm_7 =    tf.keras.layers.BatchNormalization()\n",
    "\n",
    "    self.dense_8 = tf.keras.layers.Dense(units=1000, activation='relu')\n",
    "    self.drop_8 = tf.keras.layers.Dropout(rate=0.4)\n",
    "    self.norm_8 =    tf.keras.layers.BatchNormalization()\n",
    "\n",
    "    self.classifier =  tf.keras.layers.Dense(8, activation='softmax')  # length-10 output for classification\n",
    "\n",
    "\n",
    "  def call(self, x):\n",
    "    # ...\n",
    "\n",
    "    x= self.conv_1(x)\n",
    "    x= self.pool_1(x)\n",
    "    x= self.norm_1(x)\n",
    "    \n",
    "    x= self.conv_2(x)\n",
    "    x= self.pool_2(x)\n",
    "    x= self.norm_2(x)\n",
    "\n",
    "    x= self.conv_3(x)\n",
    "    x= self.norm_3(x)\n",
    "\n",
    "    x= self.conv_4(x)\n",
    "    x= self.norm_4(x)\n",
    "\n",
    "\n",
    "    x= self.conv_5(x)\n",
    "    x= self.pool_5(x)\n",
    "    x= self.norm_5(x)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #self.block_5 =    tf.keras.layers.Conv2D(filters=64, kernel_size=3, strides=2, padding='same', activation='relu')\n",
    "    x= self.flat(x)\n",
    "\n",
    "    x= self.dense_6(x)  \n",
    "    x= self.drop_6(x)  \n",
    "    x= self.norm_6(x)   \n",
    "\n",
    "    x= self.dense_7(x)  \n",
    "    x= self.drop_7(x)  \n",
    "    x= self.norm_7(x)   \n",
    "\n",
    "    x= self.dense_8(x) \n",
    "    x= self.drop_8(x)  \n",
    "    x= self.norm_8(x)    \n",
    "\n",
    "    x = self.classifier(x) \n",
    "\n",
    "    #x += input_tensor\n",
    "    return x\n",
    "\n",
    "\n",
    "\n",
    "alexnet = Alexnet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ms1Fz9Bp_GC2"
   },
   "source": [
    "# VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wBFyF5xvceiB"
   },
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/cdeotte/how-to-choose-cnn-architecture-mnist\n",
    "# best model classify mnist? 784 - [32C3-32C3-32C5S2] - [64C3-64C3-64C5S2] - 128 - 10\n",
    "\n",
    "\n",
    "class VGG16(tf.keras.Model):\n",
    "  def __init__(self):\n",
    "    super(VGG16, self).__init__()\n",
    "\n",
    "    self.conv_1 =    tf.keras.layers.Conv2D(filters=64, kernel_size=3, strides=1, padding='same', activation='relu')\n",
    "    self.conv_12 =    tf.keras.layers.Conv2D(filters=64, kernel_size=3, strides=1, padding='same', activation='relu')\n",
    "    self.pool_1 =    tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2),padding=\"valid\")\n",
    "    \n",
    "\n",
    "    self.conv_2 =    tf.keras.layers.Conv2D(filters=128, kernel_size=3, strides=1, padding='same', activation='relu')\n",
    "    self.conv_22 =    tf.keras.layers.Conv2D(filters=128, kernel_size=3, strides=1, padding='same', activation='relu')\n",
    "    self.pool_2 =    tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2),padding=\"valid\")\n",
    "\n",
    "\n",
    "    self.conv_3 =    tf.keras.layers.Conv2D(filters=256, kernel_size=3, strides=1, padding='same', activation='relu')\n",
    "    self.conv_32 =    tf.keras.layers.Conv2D(filters=256, kernel_size=3, strides=1, padding='same', activation='relu')\n",
    "    self.conv_33 =    tf.keras.layers.Conv2D(filters=256, kernel_size=3, strides=1, padding='same', activation='relu')\n",
    "    self.pool_3 =    tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2),padding=\"valid\")\n",
    "\n",
    "\n",
    "\n",
    "    self.conv_4 =    tf.keras.layers.Conv2D(filters=512, kernel_size=3, strides=1, padding='same', activation='relu')\n",
    "    self.conv_42 =    tf.keras.layers.Conv2D(filters=512, kernel_size=3, strides=1, padding='same', activation='relu')\n",
    "    self.conv_43 =    tf.keras.layers.Conv2D(filters=512, kernel_size=3, strides=1, padding='same', activation='relu')\n",
    "    self.pool_4 =    tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2),padding=\"valid\")\n",
    "\n",
    "\n",
    "\n",
    "    self.conv_5 =    tf.keras.layers.Conv2D(filters=512, kernel_size=3, strides=1, padding='same', activation='relu')\n",
    "    self.conv_52 =    tf.keras.layers.Conv2D(filters=512, kernel_size=3, strides=1, padding='same', activation='relu')\n",
    "    self.conv_53 =    tf.keras.layers.Conv2D(filters=512, kernel_size=3, strides=1, padding='same', activation='relu')\n",
    "    self.pool_5 =    tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2),padding=\"valid\")\n",
    "\n",
    "\n",
    "\n",
    "######################## dense ######################################\n",
    "\n",
    "    self.flat = tf.keras.layers.Flatten()\n",
    "\n",
    "    self.dense_6 = tf.keras.layers.Dense(units=4096, activation='relu')\n",
    "    self.drop_6 = tf.keras.layers.Dropout(rate=0.4)\n",
    "    self.norm_6 =    tf.keras.layers.BatchNormalization()\n",
    "\n",
    "    self.dense_7 = tf.keras.layers.Dense(units=4096, activation='relu')\n",
    "    self.drop_7 = tf.keras.layers.Dropout(rate=0.4)\n",
    "    self.norm_7 =    tf.keras.layers.BatchNormalization()\n",
    "\n",
    "    self.dense_8= tf.keras.layers.Dense(units=4096, activation='relu')\n",
    "    self.drop_8 = tf.keras.layers.Dropout(rate=0.4)\n",
    "    self.norm_8 = tf.keras.layers.BatchNormalization()\n",
    "\n",
    "    self.classifier =  tf.keras.layers.Dense(8, activation='softmax')  # length-10 output for classification\n",
    "\n",
    "\n",
    "  def call(self, x):\n",
    "    \n",
    "    x= self.conv_1(x)\n",
    "    x= self.conv_12(x)\n",
    "    x= self.pool_1(x)\n",
    "    \n",
    "    x= self.conv_2(x)\n",
    "    x= self.conv_22(x)\n",
    "    x= self.pool_2(x)\n",
    "    \n",
    "\n",
    "    x= self.conv_3(x)\n",
    "    x= self.conv_32(x)\n",
    "    x= self.conv_32(x)\n",
    "    x= self.pool_3(x)\n",
    "\n",
    "\n",
    "    x= self.conv_4(x)\n",
    "    x= self.conv_42(x)\n",
    "    x= self.conv_42(x)\n",
    "    x= self.pool_4(x)\n",
    "\n",
    "\n",
    "    x= self.conv_5(x)\n",
    "    x= self.conv_52(x)\n",
    "    x= self.conv_53(x)\n",
    "    x= self.pool_5(x)\n",
    "            \n",
    "  ######## flatten #################\n",
    "\n",
    "    x= self.flat(x)\n",
    "\n",
    "    x= self.dense_6(x)  \n",
    "    x= self.drop_6(x)  \n",
    "    x= self.norm_6(x)   \n",
    "\n",
    "    x= self.dense_7(x)  \n",
    "    x= self.drop_7(x)  \n",
    "    x= self.norm_7(x)   \n",
    "\n",
    "    x= self.dense_8(x) \n",
    "    x= self.drop_8(x)  \n",
    "    x= self.norm_8(x)    \n",
    "\n",
    "    x = self.classifier(x) \n",
    "\n",
    "    #x += input_tensor\n",
    "    return x\n",
    "\n",
    "\n",
    "\n",
    "vgg16 = VGG16()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oua5hc9kiYs9"
   },
   "source": [
    "# forward model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1n80Zai2kwzX"
   },
   "outputs": [],
   "source": [
    "def forward_model_RGB(x_batch):\n",
    "\n",
    "  physical_out = physical_layer_RGB(x_batch)\n",
    "  return alexnet(physical_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DctwEiyMkwow"
   },
   "outputs": [],
   "source": [
    "def forward_model_phase_mask(x_batch):\n",
    "  physical_out = physical_layer_phase_mask(x_batch)\n",
    "  return alexnet(physical_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LZ6wPlJvpwYx"
   },
   "source": [
    "# define loss and train test step "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FnSD6Kx9cehP"
   },
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5B17Eer-cegR"
   },
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
    "\n",
    "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fXTsOCiHcea3"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(images, labels):\n",
    "\n",
    "  ## add physical layer in here?????\n",
    "  #### i fix the physical layer for now, just to make sure the cnn is running\n",
    "  #print('aaa')\n",
    "\n",
    "  #####\n",
    "  with tf.GradientTape() as tape:    \n",
    "    print('bbb')\n",
    "    #tape.watch(input_illumination_phase)\n",
    "    tape.watch(real_aperture_mask)\n",
    "    #tape.watch(color_filter_)\n",
    "    #predictions = model(images)\n",
    "    print('ccc')\n",
    "\n",
    "    #predictions = forward_model(images,input_illumination_phase,aperture_phase)\n",
    "    predictions = forward_model_phase_mask(images)\n",
    "    #predictions = forward_model_RGB(images)\n",
    "    \n",
    "    print('ddd')\n",
    "  \n",
    "    #predictions = forward_model_RGB(images,aperture_phase)\n",
    "    #predictions = model(images)\n",
    "    loss = loss_object(labels, predictions)\n",
    "    #gradients_aperture = tf.gradients(loss, aperture_phase)\n",
    "    print('ggg')\n",
    "\n",
    "\n",
    "  gradients = tape.gradient(loss, alexnet.trainable_variables +[real_aperture_mask] )\n",
    "  optimizer.apply_gradients(zip(gradients, alexnet.trainable_variables+ [real_aperture_mask]))\n",
    "  #gradients = tape.gradient(loss,alexnet.trainable_variables + [ aperture_phase] )\n",
    "  #optimizer.apply_gradients(zip(gradients,alexnet.trainable_variables+[ aperture_phase]))\n",
    "  \n",
    "  print('fff')\n",
    "  #optimizer.apply_gradients(gradients_input_illum, input_illumination_phase)\n",
    "\n",
    "  train_loss(loss)\n",
    "  train_accuracy(labels, predictions)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I7oZCzF3ceW4"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def test_step(images, labels):\n",
    "###  \n",
    "##\n",
    "  print('test step')\n",
    "  #predictions = forward_model(images,input_illumination,aperture)\n",
    "  #predictions = forward_model_RGB(images)\n",
    "\n",
    "  predictions = forward_model_phase_mask(images)\n",
    "  #predictions = model(images)\n",
    "  t_loss = loss_object(labels, predictions)\n",
    "\n",
    "  test_loss(t_loss)\n",
    "  test_accuracy(labels, predictions)\n",
    "  print(test_accuracy.result())\n",
    "  #print(test_accuracy.result().eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "24C6PazOceUV"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M0FbllXJ7qfs"
   },
   "source": [
    "# training!!!!!!! gogogo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "6711K7Y2c1RG",
    "outputId": "639273fb-068a-4980-bd28-4595f15a9e36"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bbb\n",
      "ccc\n",
      "aaa\n",
      "ccc\n",
      "ddd\n",
      "eee\n",
      "fff\n",
      "ddd\n",
      "ggg\n",
      "fff\n",
      "bbb\n",
      "ccc\n",
      "aaa\n",
      "ccc\n",
      "ddd\n",
      "eee\n",
      "fff\n",
      "ddd\n",
      "ggg\n",
      "fff\n",
      "Epoch 1, Total iteration 20, Train Loss: 2.0580685138702393, Train Accuracy: 15.3125\n",
      "Epoch 1, Total iteration 40, Train Loss: 1.8643805980682373, Train Accuracy: 23.4375\n",
      "Epoch 1, Total iteration 60, Train Loss: 1.721089482307434, Train Accuracy: 26.92708396911621\n",
      "Epoch 1, Total iteration 80, Train Loss: 1.664673089981079, Train Accuracy: 29.570310592651367\n",
      "Epoch 1, Total iteration 100, Train Loss: 1.6099064350128174, Train Accuracy: 30.71875\n",
      "bbb\n",
      "ccc\n",
      "aaa\n",
      "ccc\n",
      "ddd\n",
      "eee\n",
      "fff\n",
      "ddd\n",
      "ggg\n",
      "fff\n",
      "test step\n",
      "aaa\n",
      "ccc\n",
      "ddd\n",
      "eee\n",
      "fff\n",
      "Tensor(\"Identity_2:0\", shape=(), dtype=float32)\n",
      "Epoch 1, Total iteration 20, Test Loss: 1.1972310543060303, Test Accuracy: 37.03125\n",
      "test step\n",
      "aaa\n",
      "ccc\n",
      "ddd\n",
      "eee\n",
      "fff\n",
      "Tensor(\"Identity_2:0\", shape=(), dtype=float32)\n",
      "Epoch 1, Total iteration 40, Test Loss: 1.1954905986785889, Test Accuracy: 39.439998626708984\n",
      "Epoch 1, Loss: 1.5568947792053223, Accuracy: 32.34666442871094, Test Loss: 1.1954905986785889, Test Accuracy: 39.439998626708984\n",
      "Epoch 2, Total iteration 20, Train Loss: 1.2888325452804565, Train Accuracy: 42.34375\n",
      "Epoch 2, Total iteration 40, Train Loss: 1.2458611726760864, Train Accuracy: 42.265625\n",
      "Epoch 2, Total iteration 60, Train Loss: 1.2196574211120605, Train Accuracy: 42.447914123535156\n",
      "Epoch 2, Total iteration 80, Train Loss: 1.2097476720809937, Train Accuracy: 43.4375\n",
      "Epoch 2, Total iteration 100, Train Loss: 1.198957920074463, Train Accuracy: 43.90625\n",
      "Epoch 2, Total iteration 20, Test Loss: 1.118416428565979, Test Accuracy: 52.03125\n",
      "Epoch 2, Total iteration 40, Test Loss: 1.1145397424697876, Test Accuracy: 51.36000061035156\n",
      "Epoch 2, Loss: 1.1841635704040527, Accuracy: 44.186668395996094, Test Loss: 1.1145397424697876, Test Accuracy: 51.36000061035156\n",
      "Epoch 3, Total iteration 20, Train Loss: 1.1250190734863281, Train Accuracy: 45.625\n",
      "Epoch 3, Total iteration 40, Train Loss: 1.1353552341461182, Train Accuracy: 45.46875\n",
      "Epoch 3, Total iteration 60, Train Loss: 1.1254409551620483, Train Accuracy: 46.40625\n",
      "Epoch 3, Total iteration 80, Train Loss: 1.0973753929138184, Train Accuracy: 48.125\n",
      "Epoch 3, Total iteration 100, Train Loss: 1.1011332273483276, Train Accuracy: 47.6875\n",
      "Epoch 3, Total iteration 20, Test Loss: 1.0726045370101929, Test Accuracy: 46.71875\n",
      "Epoch 3, Total iteration 40, Test Loss: 1.0873481035232544, Test Accuracy: 47.44000244140625\n",
      "Epoch 3, Loss: 1.094401240348816, Accuracy: 47.46666717529297, Test Loss: 1.0873481035232544, Test Accuracy: 47.44000244140625\n",
      "Epoch 4, Total iteration 20, Train Loss: 1.0654325485229492, Train Accuracy: 46.09375\n",
      "Epoch 4, Total iteration 40, Train Loss: 1.0607669353485107, Train Accuracy: 48.203125\n",
      "Epoch 4, Total iteration 60, Train Loss: 1.0452663898468018, Train Accuracy: 50.36458206176758\n",
      "Epoch 4, Total iteration 80, Train Loss: 1.0378059148788452, Train Accuracy: 50.5078125\n",
      "Epoch 4, Total iteration 100, Train Loss: 1.0376430749893188, Train Accuracy: 50.5625\n",
      "Epoch 4, Total iteration 20, Test Loss: 1.0123851299285889, Test Accuracy: 54.375\n",
      "Epoch 4, Total iteration 40, Test Loss: 1.0266685485839844, Test Accuracy: 52.560001373291016\n",
      "Epoch 4, Loss: 1.0213861465454102, Accuracy: 51.33333206176758, Test Loss: 1.0266685485839844, Test Accuracy: 52.560001373291016\n",
      "Epoch 5, Total iteration 20, Train Loss: 1.0676969289779663, Train Accuracy: 48.90625\n",
      "Epoch 5, Total iteration 40, Train Loss: 1.0376231670379639, Train Accuracy: 49.296875\n",
      "Epoch 5, Total iteration 60, Train Loss: 1.0326722860336304, Train Accuracy: 50.156246185302734\n",
      "Epoch 5, Total iteration 80, Train Loss: 1.016202688217163, Train Accuracy: 51.132808685302734\n",
      "Epoch 5, Total iteration 100, Train Loss: 1.00360107421875, Train Accuracy: 51.75\n",
      "Epoch 5, Total iteration 20, Test Loss: 0.9823102951049805, Test Accuracy: 59.0625\n",
      "Epoch 5, Total iteration 40, Test Loss: 0.9895283579826355, Test Accuracy: 57.92000198364258\n",
      "Epoch 5, Loss: 0.9958478808403015, Accuracy: 52.186668395996094, Test Loss: 0.9895283579826355, Test Accuracy: 57.92000198364258\n",
      "Epoch 6, Total iteration 20, Train Loss: 0.938437283039093, Train Accuracy: 56.093753814697266\n",
      "Epoch 6, Total iteration 40, Train Loss: 0.9652243852615356, Train Accuracy: 56.796871185302734\n",
      "Epoch 6, Total iteration 60, Train Loss: 0.9638788104057312, Train Accuracy: 55.46875\n",
      "Epoch 6, Total iteration 80, Train Loss: 0.9639765024185181, Train Accuracy: 55.703128814697266\n",
      "Epoch 6, Total iteration 100, Train Loss: 0.9557886719703674, Train Accuracy: 56.0625\n",
      "Epoch 6, Total iteration 20, Test Loss: 1.2879902124404907, Test Accuracy: 45.78125\n",
      "Epoch 6, Total iteration 40, Test Loss: 1.2630794048309326, Test Accuracy: 45.52000045776367\n",
      "Epoch 6, Loss: 0.9496995210647583, Accuracy: 56.37333297729492, Test Loss: 1.2630794048309326, Test Accuracy: 45.52000045776367\n",
      "Epoch 7, Total iteration 20, Train Loss: 0.9781732559204102, Train Accuracy: 57.34375\n",
      "Epoch 7, Total iteration 40, Train Loss: 0.9385896921157837, Train Accuracy: 58.046878814697266\n",
      "Epoch 7, Total iteration 60, Train Loss: 0.9268856048583984, Train Accuracy: 57.39583206176758\n",
      "Epoch 7, Total iteration 80, Train Loss: 0.936259388923645, Train Accuracy: 56.8359375\n",
      "Epoch 7, Total iteration 100, Train Loss: 0.9358673095703125, Train Accuracy: 57.3125\n",
      "Epoch 7, Total iteration 20, Test Loss: 1.7216989994049072, Test Accuracy: 35.15625\n",
      "Epoch 7, Total iteration 40, Test Loss: 1.7097692489624023, Test Accuracy: 35.28000259399414\n",
      "Epoch 7, Loss: 0.9471226930618286, Accuracy: 56.480003356933594, Test Loss: 1.7097692489624023, Test Accuracy: 35.28000259399414\n",
      "Epoch 8, Total iteration 20, Train Loss: 1.0032809972763062, Train Accuracy: 55.78125\n",
      "Epoch 8, Total iteration 40, Train Loss: 0.9814318418502808, Train Accuracy: 56.171875\n",
      "Epoch 8, Total iteration 60, Train Loss: 0.9528769254684448, Train Accuracy: 56.041664123535156\n",
      "Epoch 8, Total iteration 80, Train Loss: 0.9326342344284058, Train Accuracy: 56.953125\n",
      "Epoch 8, Total iteration 100, Train Loss: 0.9170512557029724, Train Accuracy: 57.656253814697266\n",
      "Epoch 8, Total iteration 20, Test Loss: 0.9810270071029663, Test Accuracy: 57.656253814697266\n",
      "Epoch 8, Total iteration 40, Test Loss: 0.9888337254524231, Test Accuracy: 57.12000274658203\n",
      "Epoch 8, Loss: 0.9084437489509583, Accuracy: 58.47999954223633, Test Loss: 0.9888337254524231, Test Accuracy: 57.12000274658203\n",
      "Epoch 9, Total iteration 20, Train Loss: 0.7993481755256653, Train Accuracy: 62.343753814697266\n",
      "Epoch 9, Total iteration 40, Train Loss: 0.79933762550354, Train Accuracy: 64.0625\n",
      "Epoch 9, Total iteration 60, Train Loss: 0.8342825770378113, Train Accuracy: 62.86458206176758\n",
      "Epoch 9, Total iteration 80, Train Loss: 0.8522356748580933, Train Accuracy: 61.953128814697266\n",
      "Epoch 9, Total iteration 100, Train Loss: 0.8602575659751892, Train Accuracy: 62.0\n",
      "Epoch 9, Total iteration 20, Test Loss: 0.8630713224411011, Test Accuracy: 65.625\n",
      "Epoch 9, Total iteration 40, Test Loss: 0.8696504831314087, Test Accuracy: 63.279998779296875\n",
      "Epoch 9, Loss: 0.8626867532730103, Accuracy: 61.733333587646484, Test Loss: 0.8696504831314087, Test Accuracy: 63.279998779296875\n",
      "Epoch 10, Total iteration 20, Train Loss: 0.8012934923171997, Train Accuracy: 64.21875\n",
      "Epoch 10, Total iteration 40, Train Loss: 0.8085185885429382, Train Accuracy: 63.671875\n",
      "Epoch 10, Total iteration 60, Train Loss: 0.8189858794212341, Train Accuracy: 63.489585876464844\n",
      "Epoch 10, Total iteration 80, Train Loss: 0.8118795156478882, Train Accuracy: 63.984375\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "train_acc_list = []\n",
    "test_acc_list = []\n",
    "train_loss_list = []\n",
    "test_loss_list = []\n",
    "\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "  # Reset the metrics at the start of the next epoch\n",
    "  train_loss.reset_states()\n",
    "  train_accuracy.reset_states()\n",
    "  test_loss.reset_states()\n",
    "  test_accuracy.reset_states()\n",
    "  i = 0\n",
    "  for images, labels in train_ds:\n",
    "    i = i+1 # total 1875 batches for training data\n",
    "    #print('i',i)\n",
    "    images = images.numpy()\n",
    "    labels = labels.numpy()\n",
    "    #images = tf.cast(images, tf.float32)\n",
    "    #print(images)\n",
    "    train_step(images, labels)\n",
    "    if i%20 == 0:\n",
    "      template_train = 'Epoch {}, Total iteration {}, Train Loss: {}, Train Accuracy: {}'\n",
    "      print(template_train.format(epoch+1, i, train_loss.result(), train_accuracy.result()*100))\n",
    "      ## monitor the illuminace phase and aperture phase\n",
    "  t = 0\n",
    "  for test_images, test_labels in test_ds:\n",
    "    t = t + 1 \n",
    "    #print('t',t)\n",
    "    test_step(test_images, test_labels)\n",
    "    if t%20 == 0:\n",
    "      template_test = 'Epoch {}, Total iteration {}, Test Loss: {}, Test Accuracy: {}'\n",
    "      print(template_test.format(epoch+1, t, test_loss.result(), test_accuracy.result()*100))\n",
    "  template = 'Epoch {}, Loss: {}, Accuracy: {}, Test Loss: {}, Test Accuracy: {}'\n",
    "  print(template.format(epoch+1,\n",
    "                        train_loss.result(),\n",
    "                        train_accuracy.result()*100,\n",
    "                        test_loss.result(),\n",
    "                        test_accuracy.result()*100))\n",
    "  test_acc_list.append(test_accuracy.result()*100)\n",
    "  train_acc_list.append(train_accuracy.result()*100)\n",
    "  test_loss_list.append(test_loss.result())\n",
    "  train_loss_list.append(train_loss.result())\n",
    "\n",
    "train_loss_arr = np.array(train_loss_list)\n",
    "test_loss_arr = np.array(test_loss_list)\n",
    "print('train_loss_arr',train_loss_arr)\n",
    "print('test_loss_arr',test_loss_arr)\n",
    "\n",
    "train_acc_arr = np.array(train_acc_list)\n",
    "test_acc_arr = np.array(test_acc_list)\n",
    "print('train_acc_arr',train_acc_arr)\n",
    "print('test_acc_arr',test_acc_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qwTg9gH2c1O_"
   },
   "outputs": [],
   "source": [
    "plt.plot(train_acc_arr)\n",
    "plt.plot(test_acc_arr)\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MIKRqvINvfKX"
   },
   "outputs": [],
   "source": [
    "plt.plot(train_loss_arr)\n",
    "plt.plot(test_loss_arr)\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-jXD-JGETSwg"
   },
   "outputs": [],
   "source": [
    " tf.square(real_aperture_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5LzDUxKow5J0"
   },
   "outputs": [],
   "source": [
    "real_aperture_mask[75,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sgQ17dk3xPuL"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LCLXhnWUc1Mx"
   },
   "outputs": [],
   "source": [
    "real_aperture_mask/tf.max(real_aperture_mask) # normalize the mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AEkjZscwc1KF"
   },
   "outputs": [],
   "source": [
    "real_aperture_mask2"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "colorectal_real_value0_1_mask_correct.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
